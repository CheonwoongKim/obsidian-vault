---
title: "[í”„ë ˆì„ì›Œí¬] AgentScope ì™„ì „ ê°€ì´ë“œ - ì•Œë¦¬ë°”ë°” ë©€í‹° ì—ì´ì „íŠ¸ í”Œë«í¼"
type: resource
category: AI/í”„ë ˆì„ì›Œí¬
tags: [agentscope, alibaba, ë©€í‹°ì—ì´ì „íŠ¸, ë“œë˜ê·¸ì•¤ë“œë¡­, ë¹„ë™ê¸°, ì•¡í„°ëª¨ë¸]
source: "ê³µì‹ ë¬¸ì„œ ë° ì‹¤ìŠµ ê¸°ë°˜ ì‘ì„±"
status: active
updated: 2025-09-24
---

## ğŸ”— ê´€ë ¨ ê°€ì´ë“œ

### ëŒ€ê·œëª¨ ë©€í‹° ì—ì´ì „íŠ¸ í”Œë«í¼
- **[í”„ë ˆì„ì›Œí¬] AgentScope ì™„ì „ ê°€ì´ë“œ - ì•Œë¦¬ë°”ë°” ë©€í‹° ì—ì´ì „íŠ¸ í”Œë«í¼** â† **í˜„ì¬ ê°€ì´ë“œ**
- **[[í”„ë ˆì„ì›Œí¬] Google ADK]]** - êµ¬ê¸€ ì—ì´ì „íŠ¸ ê°œë°œ í”Œë«í¼
- **[[í”„ë ˆì„ì›Œí¬] Haystack]]** - ì—”í„°í”„ë¼ì´ì¦ˆ RAG ì†”ë£¨ì…˜

### ë©€í‹° ì—ì´ì „íŠ¸ í”„ë ˆì„ì›Œí¬
- **[[í”„ë ˆì„ì›Œí¬] AutoGen]]** - ëŒ€í™”í˜• ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œ
- **[[í”„ë ˆì„ì›Œí¬] CrewAI]]** - ì—­í•  ê¸°ë°˜ ì‘ì—… ë¶„ë‹´
- **[[í”„ë ˆì„ì›Œí¬] Phidata]]** - ë‹¤ì–‘í•œ ëª¨ë‹¬ì„ í™œìš©í•˜ëŠ” ì—ì´ì „íŠ¸

### AI í”„ë ˆì„ì›Œí¬ ì‹œë¦¬ì¦ˆ
- **[[í”„ë ˆì„ì›Œí¬] LangChain]]** - ì¢…í•© AI ì• í”Œë¦¬ì¼€ì´ì…˜ í”„ë ˆì„ì›Œí¬
- **[[í”„ë ˆì„ì›Œí¬] LangGraph]]** - ë³µì¡í•œ ì›Œí¬í”Œë¡œìš° ì„¤ê³„
- **[[í”„ë ˆì„ì›Œí¬] DSPy]]** - í”„ë¡¬í”„íŠ¸ ìµœì í™”

### í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§
- **[[í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§ - ë§ˆìŠ¤í„° ê°€ì´ë“œ]]** - ì „ì²´ í”„ë¡¬í”„íŒ… ê¸°ë²• ê°œìš”
- **[[í”„ë¡¬í”„íŠ¸] 04 ReAct í”„ë¡¬í”„íŒ…]]** - ì¶”ë¡ ê³¼ ë„êµ¬ í™œìš© ê¸°ë²•

---

# 1. ê°œìš”

AgentScopeëŠ” **ì•Œë¦¬ë°”ë°”ì—ì„œ ê°œë°œí•œ ì˜¤í”ˆì†ŒìŠ¤ ë©€í‹° ì—ì´ì „íŠ¸ í”Œë«í¼**ìœ¼ë¡œ, **ì—ì´ì „íŠ¸ ì§€í–¥ í”„ë¡œê·¸ë˜ë°(Agent-Oriented Programming)**ì„ í†µí•´ LLM ê¸°ë°˜ ì• í”Œë¦¬ì¼€ì´ì…˜ì„ êµ¬ì¶•í•  ìˆ˜ ìˆëŠ” í”„ë ˆì„ì›Œí¬ì…ë‹ˆë‹¤.

## í•µì‹¬ íŠ¹ì§•

### ğŸ¯ í˜ì‹ ì  ì ‘ê·¼ë²•
- **ì—ì´ì „íŠ¸ ì§€í–¥ í”„ë¡œê·¸ë˜ë°**: ìƒˆë¡œìš´ íŒ¨ëŸ¬ë‹¤ì„ì˜ AI ì• í”Œë¦¬ì¼€ì´ì…˜ ê°œë°œ
- **ë“œë˜ê·¸ ì•¤ ë“œë¡­ UI**: ì½”ë”© ì—†ì´ ë©€í‹° ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œ êµ¬ì„±
- **ì ˆì°¨ ì§€í–¥ ë©”ì‹œì§€ êµí™˜**: ì§ê´€ì ì´ê³  ì´í•´í•˜ê¸° ì‰¬ìš´ ì—ì´ì „íŠ¸ í†µì‹ 
- **ì™„ì „í•œ íˆ¬ëª…ì„±**: ëª¨ë“  í”„ë¡¬í”„íŠ¸, API í˜¸ì¶œ, ë©”ëª¨ë¦¬, ì›Œí¬í”Œë¡œìš° ê°€ì‹œí™”

### ğŸ”§ ê¸°ìˆ ì  ê°•ì 
- **ë¹„ë™ê¸° ì‹¤í–‰**: v1.0ì—ì„œ ì™„ì „í•œ ë¹„ë™ê¸° ì§€ì›
- **ì•¡í„° ëª¨ë¸**: ìë™ ë³‘ë ¬ ìµœì í™” ë° ë¶„ì‚° ì²˜ë¦¬
- **ëª¨ë¸ ì¤‘ë¦½ì **: ë‹¤ì–‘í•œ LLM ì œê³µì ì§€ì›
- **ê²¬ê³ í•œ ì•„í‚¤í…ì²˜**: ì‚¬ìš©ì ì •ì˜ ì¥ì•  í—ˆìš© ë° ì¬ì‹œë„ ë©”ì»¤ë‹ˆì¦˜

---

# 2. ì„¤ì¹˜ ë° í™˜ê²½ ì„¤ì •

## 2.1. ì‹œìŠ¤í…œ ìš”êµ¬ì‚¬í•­

```bash
# Python 3.10 ì´ìƒ í•„ìš”
python --version  # Python 3.10+ í™•ì¸

# ê°€ìƒí™˜ê²½ ìƒì„± (ê¶Œì¥)
python3 -m venv agentscope_env
source agentscope_env/bin/activate  # macOS/Linux
# agentscope_env\Scripts\activate  # Windows
```

## 2.2. ê¸°ë³¸ ì„¤ì¹˜

```bash
# PyPIì—ì„œ ì„¤ì¹˜
pip install agentscope

# ëŸ°íƒ€ì„ í”„ë ˆì„ì›Œí¬ (ì½”ì–´ ì¢…ì†ì„±)
pip install agentscope-runtime

# ìƒŒë“œë°•ìŠ¤ ì¢…ì†ì„± í¬í•¨ (ê¶Œì¥)
pip install "agentscope-runtime[sandbox]"

# ê°œë°œ ë²„ì „ ì„¤ì¹˜
git clone -b main https://github.com/agentscope-ai/agentscope.git
cd agentscope
pip install -e .
```

## 2.3. í™˜ê²½ ë³€ìˆ˜ ì„¤ì •

```bash
# .env íŒŒì¼ ìƒì„±
OPENAI_API_KEY=your-openai-api-key
DASHSCOPE_API_KEY=your-alibaba-key  # ì•Œë¦¬ë°”ë°” DashScope
GOOGLE_API_KEY=your-gemini-key      # Google Gemini
ANTHROPIC_API_KEY=your-claude-key   # Anthropic Claude

# ì„ íƒì  ì„¤ì •
AGENTSCOPE_CACHE_DIR=./cache
AGENTSCOPE_LOG_LEVEL=INFO
```

## 2.4. ì„¤ì¹˜ í™•ì¸

```python
import agentscope
from agentscope.agents import DialogAgent
from agentscope.models import OpenAIWrapperModel

print(f"âœ… AgentScope ì„¤ì¹˜ ì™„ë£Œ")
print(f"AgentScope version: {agentscope.__version__}")

# ê¸°ë³¸ ëª¨ë¸ í…ŒìŠ¤íŠ¸
model = OpenAIWrapperModel(
    model_type="gpt-4o-mini",
    config_name="test_config"
)

print("âœ… ëª¨ë¸ ë˜í¼ ìƒì„± ì„±ê³µ")
```

---

# 3. ê¸°ë³¸ ì‚¬ìš©ë²•

## 3.1. ê°„ë‹¨í•œ ì—ì´ì „íŠ¸ ìƒì„±

```python
import agentscope
from agentscope.agents import DialogAgent
from agentscope.models import OpenAIWrapperModel
from agentscope.message import Msg

# ëª¨ë¸ ì„¤ì •
model_config = {
    "config_name": "openai_config",
    "model_type": "openai_chat",
    "model": "gpt-4o-mini",
    "api_key": "your-openai-api-key"
}

# AgentScope ì´ˆê¸°í™”
agentscope.init(
    model_configs=[model_config],
    project="basic_agent_example"
)

# ì—ì´ì „íŠ¸ ìƒì„±
assistant = DialogAgent(
    name="Assistant",
    model_config_name="openai_config",
    sys_prompt="You are a helpful assistant. Answer questions clearly and concisely."
)

# ì—ì´ì „íŠ¸ì™€ ëŒ€í™”
user_msg = Msg(name="User", content="What is artificial intelligence?", role="user")
response = assistant(user_msg)

print(f"Assistant: {response.content}")
```

## 3.2. ë©€í‹° ì—ì´ì „íŠ¸ ëŒ€í™”

```python
import agentscope
from agentscope.agents import DialogAgent
from agentscope.pipeline import sequential_pipeline
from agentscope.message import Msg

# ëª¨ë¸ ì„¤ì •
model_configs = [
    {
        "config_name": "openai_config",
        "model_type": "openai_chat",
        "model": "gpt-4o-mini",
        "api_key": "your-openai-api-key"
    }
]

# AgentScope ì´ˆê¸°í™”
agentscope.init(
    model_configs=model_configs,
    project="multi_agent_example"
)

# ì—¬ëŸ¬ ì—ì´ì „íŠ¸ ìƒì„±
analyst = DialogAgent(
    name="Market_Analyst",
    model_config_name="openai_config",
    sys_prompt="You are a market analyst. Provide data-driven market insights."
)

strategist = DialogAgent(
    name="Business_Strategist",
    model_config_name="openai_config",
    sys_prompt="You are a business strategist. Create actionable business strategies."
)

consultant = DialogAgent(
    name="Consultant",
    model_config_name="openai_config",
    sys_prompt="You are a consultant. Synthesize insights and provide recommendations."
)

# ìˆœì°¨ì  íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
def business_analysis_pipeline():
    """ë¹„ì¦ˆë‹ˆìŠ¤ ë¶„ì„ íŒŒì´í”„ë¼ì¸"""

    # ì´ˆê¸° ì§ˆë¬¸
    initial_question = Msg(
        name="User",
        content="Analyze the market opportunity for AI-powered customer service automation",
        role="user"
    )

    # ì‹œì¥ ë¶„ì„
    market_analysis = analyst(initial_question)
    print(f"Market Analysis: {market_analysis.content}")

    # ì „ëµ ìˆ˜ë¦½
    strategy_input = Msg(
        name="Market_Analyst",
        content=market_analysis.content,
        role="assistant"
    )
    strategy = strategist(strategy_input)
    print(f"Business Strategy: {strategy.content}")

    # ìµœì¢… ì»¨ì„¤íŒ…
    consulting_input = Msg(
        name="Business_Strategist",
        content=f"Market Analysis: {market_analysis.content}\n\nStrategy: {strategy.content}",
        role="assistant"
    )
    final_recommendation = consultant(consulting_input)
    print(f"Final Recommendation: {final_recommendation.content}")

    return final_recommendation

# ì‹¤í–‰
result = business_analysis_pipeline()
```

## 3.3. ë¹„ë™ê¸° ë©€í‹° ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œ

```python
import asyncio
import agentscope
from agentscope.agents import DialogAgent
from agentscope.message import Msg

async def async_multi_agent_example():
    """ë¹„ë™ê¸° ë©€í‹° ì—ì´ì „íŠ¸ ì˜ˆì œ"""

    # ëª¨ë¸ ì„¤ì •
    model_configs = [
        {
            "config_name": "openai_config",
            "model_type": "openai_chat",
            "model": "gpt-4o-mini",
            "api_key": "your-openai-api-key"
        }
    ]

    # AgentScope ì´ˆê¸°í™”
    agentscope.init(
        model_configs=model_configs,
        project="async_multi_agent"
    )

    # ì—ì´ì „íŠ¸ë“¤ ìƒì„±
    researcher = DialogAgent(
        name="Researcher",
        model_config_name="openai_config",
        sys_prompt="You are a researcher. Conduct thorough research on given topics."
    )

    writer = DialogAgent(
        name="Writer",
        model_config_name="openai_config",
        sys_prompt="You are a content writer. Create engaging articles."
    )

    reviewer = DialogAgent(
        name="Reviewer",
        model_config_name="openai_config",
        sys_prompt="You are an editor. Review and improve content quality."
    )

    # ë³‘ë ¬ ì‘ì—… ì •ì˜
    async def research_task():
        msg = Msg(name="User", content="Research latest trends in AI agents", role="user")
        return await researcher(msg)

    async def writing_task():
        msg = Msg(name="User", content="Write an introduction about AI agent frameworks", role="user")
        return await writer(msg)

    async def review_task(content):
        msg = Msg(name="Writer", content=content, role="assistant")
        return await reviewer(msg)

    # ë³‘ë ¬ ì‹¤í–‰
    research_result, writing_result = await asyncio.gather(
        research_task(),
        writing_task()
    )

    # ìˆœì°¨ ê²€í† 
    final_review = await review_task(
        f"Research: {research_result.content}\n\nContent: {writing_result.content}"
    )

    return {
        "research": research_result.content,
        "writing": writing_result.content,
        "review": final_review.content
    }

# ì‹¤í–‰
result = asyncio.run(async_multi_agent_example())
print("ë¹„ë™ê¸° ë©€í‹° ì—ì´ì „íŠ¸ ê²°ê³¼:", result)
```

---

# 4. ê³ ê¸‰ í™œìš©ë²•

## 4.1. MsgHubë¥¼ í™œìš©í•œ ë³µì¡í•œ í†µì‹ 

```python
import agentscope
from agentscope.agents import DialogAgent
from agentscope.pipeline import MsgHub
from agentscope.message import Msg
from agentscope.models import OpenAIWrapperModel

class TeamCollaborationSystem:
    def __init__(self):
        self.setup_agents()
        self.setup_hub()

    def setup_agents(self):
        """íŒ€ ì—ì´ì „íŠ¸ë“¤ ì„¤ì •"""

        # ëª¨ë¸ ì„¤ì •
        model_configs = [
            {
                "config_name": "openai_config",
                "model_type": "openai_chat",
                "model": "gpt-4o",
                "api_key": "your-openai-api-key"
            }
        ]

        agentscope.init(
            model_configs=model_configs,
            project="team_collaboration"
        )

        # íŒ€ ë¦¬ë”
        self.team_leader = DialogAgent(
            name="Team_Leader",
            model_config_name="openai_config",
            sys_prompt="""You are a team leader. Your responsibilities:
            1. Coordinate team activities
            2. Make final decisions
            3. Delegate tasks appropriately
            4. Ensure project success"""
        )

        # ê°œë°œì
        self.developer = DialogAgent(
            name="Developer",
            model_config_name="openai_config",
            sys_prompt="""You are a senior developer. Your expertise:
            1. Technical architecture and implementation
            2. Code quality and best practices
            3. Performance optimization
            4. Technical problem solving"""
        )

        # ë””ìì´ë„ˆ
        self.designer = DialogAgent(
            name="Designer",
            model_config_name="openai_config",
            sys_prompt="""You are a UX/UI designer. Your focus:
            1. User experience and interface design
            2. Visual aesthetics and branding
            3. Usability and accessibility
            4. Design system consistency"""
        )

        # ë§ˆì¼€í„°
        self.marketer = DialogAgent(
            name="Marketer",
            model_config_name="openai_config",
            sys_prompt="""You are a marketing specialist. Your areas:
            1. Market research and user insights
            2. Brand positioning and messaging
            3. Campaign strategy and execution
            4. Growth and conversion optimization"""
        )

    def setup_hub(self):
        """ë©”ì‹œì§€ í—ˆë¸Œ ì„¤ì •"""
        self.hub = MsgHub(
            participants=[
                self.team_leader,
                self.developer,
                self.designer,
                self.marketer
            ],
            announcement_condition=lambda: True
        )

    def collaborate_on_project(self, project_brief: str):
        """í”„ë¡œì íŠ¸ í˜‘ì—… ì‹œë®¬ë ˆì´ì…˜"""

        # í”„ë¡œì íŠ¸ ì‹œì‘ ë©”ì‹œì§€
        initial_msg = Msg(
            name="Project_Manager",
            content=f"New Project Brief: {project_brief}\n\n"
                   f"Team, please provide your perspectives and initial thoughts on this project.",
            role="user"
        )

        # í—ˆë¸Œë¥¼ í†µí•œ ë©”ì‹œì§€ ë°°í¬
        self.hub.broadcast(initial_msg)

        # ê° íŒ€ì›ì˜ ì‘ë‹µ ìˆ˜ì§‘
        responses = {}

        # ê°œë°œì ê´€ì 
        dev_response = self.developer(initial_msg)
        responses['developer'] = dev_response.content

        # ë””ìì´ë„ˆ ê´€ì 
        design_response = self.designer(initial_msg)
        responses['designer'] = design_response.content

        # ë§ˆì¼€í„° ê´€ì 
        marketing_response = self.marketer(initial_msg)
        responses['marketer'] = marketing_response.content

        # íŒ€ ë¦¬ë”ê°€ ëª¨ë“  ì˜ê²¬ì„ ì¢…í•©
        synthesis_msg = Msg(
            name="Team",
            content=f"""Team responses to project brief:

            Developer perspective: {responses['developer']}

            Designer perspective: {responses['designer']}

            Marketing perspective: {responses['marketer']}

            As team leader, please synthesize these perspectives and create a comprehensive project plan.""",
            role="assistant"
        )

        final_plan = self.team_leader(synthesis_msg)

        return {
            'project_brief': project_brief,
            'team_responses': responses,
            'final_plan': final_plan.content
        }

# ì‚¬ìš© ì˜ˆì œ
team_system = TeamCollaborationSystem()

project_result = team_system.collaborate_on_project(
    "ê°œë°œ ëª©í‘œ: AI ê¸°ë°˜ ê°œì¸í™” í•™ìŠµ í”Œë«í¼ êµ¬ì¶•\n"
    "- íƒ€ê²Ÿ: ëŒ€í•™ìƒ ë° ì§ì¥ì¸\n"
    "- í•µì‹¬ ê¸°ëŠ¥: ê°œì¸ë§ì¶¤ í•™ìŠµê²½ë¡œ, ì§„ë„ì¶”ì , AI íŠœí„°\n"
    "- ëŸ°ì¹­ ëª©í‘œ: 3ê°œì›” ë‚´"
)

print("=== í”„ë¡œì íŠ¸ í˜‘ì—… ê²°ê³¼ ===")
print(f"í”„ë¡œì íŠ¸ ê°œìš”: {project_result['project_brief']}")
print(f"\nê°œë°œì ì˜ê²¬: {project_result['team_responses']['developer']}")
print(f"\në””ìì´ë„ˆ ì˜ê²¬: {project_result['team_responses']['designer']}")
print(f"\në§ˆì¼€í„° ì˜ê²¬: {project_result['team_responses']['marketer']}")
print(f"\níŒ€ ë¦¬ë” ìµœì¢… ê³„íš: {project_result['final_plan']}")
```

## 4.2. ë‚´ì¥ ë„êµ¬ í™œìš©

```python
import agentscope
from agentscope.agents import DialogAgent
from agentscope.tools import execute_python_code, execute_shell_command, write_text_file
from agentscope.message import Msg

class DataAnalysisAgent:
    def __init__(self):
        self.setup_agent()

    def setup_agent(self):
        """ë°ì´í„° ë¶„ì„ ì—ì´ì „íŠ¸ ì„¤ì •"""

        model_configs = [
            {
                "config_name": "openai_config",
                "model_type": "openai_chat",
                "model": "gpt-4o",
                "api_key": "your-openai-api-key"
            }
        ]

        agentscope.init(
            model_configs=model_configs,
            project="data_analysis"
        )

        # ë„êµ¬ê°€ ìˆëŠ” ì—ì´ì „íŠ¸
        self.analyst = DialogAgent(
            name="Data_Analyst",
            model_config_name="openai_config",
            sys_prompt="""You are a data analyst with access to programming tools.
            You can execute Python code, shell commands, and write files.

            Available tools:
            - execute_python_code: Run Python code for data analysis
            - execute_shell_command: Run system commands
            - write_text_file: Save results to files

            Always explain your analysis process and interpret results."""
        )

        # ë„êµ¬ ë“±ë¡
        self.tools = {
            'python': execute_python_code,
            'shell': execute_shell_command,
            'write_file': write_text_file
        }

    def analyze_data(self, data_description: str, analysis_task: str):
        """ë°ì´í„° ë¶„ì„ ìˆ˜í–‰"""

        # ë¶„ì„ ìš”ì²­ ë©”ì‹œì§€
        analysis_msg = Msg(
            name="User",
            content=f"""Data Description: {data_description}

            Analysis Task: {analysis_task}

            Please perform the analysis using Python code. Include:
            1. Data exploration and visualization
            2. Statistical analysis
            3. Key insights and findings
            4. Recommendations based on results""",
            role="user"
        )

        # ë¶„ì„ ì‹¤í–‰
        response = self.analyst(analysis_msg)

        # Python ì½”ë“œ ì‹¤í–‰ (ì˜ˆì‹œ)
        analysis_code = """
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

# ìƒ˜í”Œ ë°ì´í„° ìƒì„± (ì‹¤ì œë¡œëŠ” ì œê³µëœ ë°ì´í„° ì‚¬ìš©)
np.random.seed(42)
data = {
    'month': range(1, 13),
    'sales': np.random.normal(100000, 20000, 12),
    'marketing_spend': np.random.normal(10000, 2000, 12),
    'customer_satisfaction': np.random.uniform(3.5, 5.0, 12)
}

df = pd.DataFrame(data)
df['sales'] = df['sales'].clip(lower=50000)  # ìµœì†Œê°’ ì„¤ì •

# ê¸°ë³¸ í†µê³„
print("=== ê¸°ë³¸ í†µê³„ ===")
print(df.describe())

# ìƒê´€ê´€ê³„ ë¶„ì„
print("\\n=== ìƒê´€ê´€ê³„ ===")
correlation_matrix = df.corr()
print(correlation_matrix)

# ì‹œê°í™”
plt.figure(figsize=(15, 5))

plt.subplot(1, 3, 1)
plt.plot(df['month'], df['sales'], marker='o')
plt.title('Monthly Sales Trend')
plt.xlabel('Month')
plt.ylabel('Sales')

plt.subplot(1, 3, 2)
plt.scatter(df['marketing_spend'], df['sales'])
plt.title('Marketing Spend vs Sales')
plt.xlabel('Marketing Spend')
plt.ylabel('Sales')

plt.subplot(1, 3, 3)
plt.scatter(df['customer_satisfaction'], df['sales'])
plt.title('Customer Satisfaction vs Sales')
plt.xlabel('Customer Satisfaction')
plt.ylabel('Sales')

plt.tight_layout()
plt.savefig('analysis_results.png', dpi=150, bbox_inches='tight')
plt.show()

# ì£¼ìš” ì¸ì‚¬ì´íŠ¸
total_sales = df['sales'].sum()
avg_satisfaction = df['customer_satisfaction'].mean()
sales_marketing_corr = df['sales'].corr(df['marketing_spend'])

print(f"\\n=== ì£¼ìš” ì¸ì‚¬ì´íŠ¸ ===")
print(f"ì—°ê°„ ì´ ë§¤ì¶œ: ${total_sales:,.0f}")
print(f"í‰ê·  ê³ ê° ë§Œì¡±ë„: {avg_satisfaction:.2f}/5.0")
print(f"ë§¤ì¶œ-ë§ˆì¼€íŒ…ë¹„ìš© ìƒê´€ê³„ìˆ˜: {sales_marketing_corr:.3f}")
"""

        # ì½”ë“œ ì‹¤í–‰
        code_result = execute_python_code(analysis_code)

        # ê²°ê³¼ íŒŒì¼ ì €ì¥
        report_content = f"""
ë°ì´í„° ë¶„ì„ ë³´ê³ ì„œ
==================

ë¶„ì„ ìš”ì²­: {analysis_task}
ë°ì´í„° ì„¤ëª…: {data_description}

AI ë¶„ì„ ê²°ê³¼:
{response.content}

Python ë¶„ì„ ê²°ê³¼:
{code_result}

ìƒì„±ì¼ì‹œ: {pd.Timestamp.now()}
"""

        write_text_file("analysis_report.txt", report_content)

        return {
            'ai_analysis': response.content,
            'code_result': code_result,
            'report_saved': True
        }

# ì‚¬ìš© ì˜ˆì œ
data_analyst = DataAnalysisAgent()

analysis_result = data_analyst.analyze_data(
    data_description="ì›”ë³„ íŒë§¤ ë°ì´í„°, ë§ˆì¼€íŒ… ì§€ì¶œ, ê³ ê° ë§Œì¡±ë„ ë°ì´í„° (12ê°œì›”)",
    analysis_task="íŒë§¤ ì„±ê³¼ ë¶„ì„ ë° ë§ˆì¼€íŒ… ROI í‰ê°€, ê°œì„  ë°©ì•ˆ ì œì‹œ"
)

print("=== ë¶„ì„ ê²°ê³¼ ===")
print(analysis_result['ai_analysis'])
print("\n=== ì½”ë“œ ì‹¤í–‰ ê²°ê³¼ ===")
print(analysis_result['code_result'])
```

---

# 5. ì‹¤ì œ í”„ë¡œì íŠ¸ ì˜ˆì œ

## 5.1. ìŠ¤ë§ˆíŠ¸ ê³ ê° ì„œë¹„ìŠ¤ ì‹œìŠ¤í…œ

```python
import agentscope
from agentscope.agents import DialogAgent
from agentscope.pipeline import MsgHub, WhileLoopPipeline
from agentscope.message import Msg
from agentscope.tools import execute_python_code
import json
from datetime import datetime
from typing import Dict, List

class SmartCustomerServiceSystem:
    def __init__(self):
        self.setup_system()
        self.ticket_database = {}
        self.knowledge_base = self.load_knowledge_base()

    def setup_system(self):
        """ê³ ê° ì„œë¹„ìŠ¤ ì‹œìŠ¤í…œ ì„¤ì •"""

        model_configs = [
            {
                "config_name": "openai_config",
                "model_type": "openai_chat",
                "model": "gpt-4o",
                "api_key": "your-openai-api-key"
            }
        ]

        agentscope.init(
            model_configs=model_configs,
            project="smart_customer_service"
        )

        # 1ì°¨ ì ‘ìˆ˜ ì—ì´ì „íŠ¸
        self.intake_agent = DialogAgent(
            name="Intake_Specialist",
            model_config_name="openai_config",
            sys_prompt="""ë‹¹ì‹ ì€ ê³ ê° ì„œë¹„ìŠ¤ ì ‘ìˆ˜ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

            ì£¼ìš” ì—­í• :
            1. ê³ ê°ì„ ë”°ëœ»í•˜ê²Œ ë§ì´í•˜ê³  ë¬¸ì œë¥¼ íŒŒì•…
            2. ë¬¸ì˜ ìœ í˜•ì„ ë¶„ë¥˜ (ê¸°ìˆ ì§€ì›, ê²°ì œ, ì¼ë°˜ë¬¸ì˜, ë¶ˆë§Œ)
            3. í•„ìš”í•œ ì •ë³´ë¥¼ ìˆ˜ì§‘
            4. ì ì ˆí•œ ì „ë¬¸ê°€ì—ê²Œ ë¼ìš°íŒ… ê²°ì •
            5. ê³ ê° ê°ì • ìƒíƒœë¥¼ íŒŒì•…í•˜ê³  ì ì ˆíˆ ì‘ëŒ€

            í•­ìƒ ì¹œê·¼í•˜ê³  ì „ë¬¸ì ìœ¼ë¡œ ì‘ë‹µí•˜ì„¸ìš”."""
        )

        # ê¸°ìˆ  ì§€ì› ì—ì´ì „íŠ¸
        self.tech_support = DialogAgent(
            name="Tech_Support",
            model_config_name="openai_config",
            sys_prompt="""ë‹¹ì‹ ì€ ê¸°ìˆ  ì§€ì› ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

            ì „ë¬¸ ë¶„ì•¼:
            1. ì†Œí”„íŠ¸ì›¨ì–´ ë¬¸ì œ í•´ê²°
            2. ë‹¨ê³„ë³„ ê°€ì´ë“œ ì œê³µ
            3. ì‹œìŠ¤í…œ ì˜¤ë¥˜ ì§„ë‹¨
            4. ì„±ëŠ¥ ìµœì í™” ì¡°ì–¸

            ë³µì¡í•œ ê¸°ìˆ  ë‚´ìš©ì„ ì‰½ê²Œ ì„¤ëª…í•˜ê³  ì‹¤ìš©ì ì¸ í•´ê²°ì±…ì„ ì œê³µí•˜ì„¸ìš”."""
        )

        # ê²°ì œ ì§€ì› ì—ì´ì „íŠ¸
        self.billing_support = DialogAgent(
            name="Billing_Support",
            model_config_name="openai_config",
            sys_prompt="""ë‹¹ì‹ ì€ ê²°ì œ ë° ê³„ì • ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

            ë‹´ë‹¹ ì—…ë¬´:
            1. ê²°ì œ ë¬¸ì œ í•´ê²°
            2. ê³„ì • ì •ë³´ ê´€ë¦¬
            3. í™˜ë¶ˆ ë° ì·¨ì†Œ ì²˜ë¦¬
            4. ìš”ê¸ˆì œ ë° ì„œë¹„ìŠ¤ ì•ˆë‚´

            ì •í™•í•œ ì •ë³´ë¥¼ ì œê³µí•˜ê³  ê³ ê°ì˜ ê¸ˆì „ì  ìš°ë ¤ë¥¼ í•´ê²°í•˜ì„¸ìš”."""
        )

        # ì—ìŠ¤ì»¬ë ˆì´ì…˜ ë§¤ë‹ˆì €
        self.escalation_manager = DialogAgent(
            name="Escalation_Manager",
            model_config_name="openai_config",
            sys_prompt="""ë‹¹ì‹ ì€ ê³ ê¸‰ ë¬¸ì œ í•´ê²° ë§¤ë‹ˆì €ì…ë‹ˆë‹¤.

            ì±…ì„ ì˜ì—­:
            1. ë³µì¡í•œ ë¬¸ì œ í•´ê²°
            2. ê³ ê° ë¶ˆë§Œ ì²˜ë¦¬
            3. ì •ì±… ì˜ˆì™¸ ê²°ì •
            4. ë³´ìƒ ë° í•´ê²°ì±… ì œì•ˆ

            ê³ ê° ë§Œì¡±ì„ ìµœìš°ì„ ìœ¼ë¡œ í•˜ë˜ íšŒì‚¬ ì´ìµë„ ê³ ë ¤í•˜ì—¬ ê· í˜•ì¡íŒ ê²°ì •ì„ ë‚´ë¦¬ì„¸ìš”."""
        )

        # í’ˆì§ˆ ë³´ì¦ ì—ì´ì „íŠ¸
        self.qa_agent = DialogAgent(
            name="Quality_Assurance",
            model_config_name="openai_config",
            sys_prompt="""ë‹¹ì‹ ì€ í’ˆì§ˆ ë³´ì¦ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

            ì—­í• :
            1. ì„œë¹„ìŠ¤ í’ˆì§ˆ ëª¨ë‹ˆí„°ë§
            2. ê³ ê° ë§Œì¡±ë„ í‰ê°€
            3. í”„ë¡œì„¸ìŠ¤ ê°œì„  ì œì•ˆ
            4. íŒ€ ì„±ê³¼ ë¶„ì„

            ê°ê´€ì ì´ê³  ê±´ì„¤ì ì¸ í”¼ë“œë°±ì„ ì œê³µí•˜ì„¸ìš”."""
        )

    def load_knowledge_base(self) -> Dict:
        """ì§€ì‹ ë² ì´ìŠ¤ ë¡œë“œ (ì‹¤ì œë¡œëŠ” ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ë¡œë“œ)"""
        return {
            "faq": [
                {"q": "ë¹„ë°€ë²ˆí˜¸ë¥¼ ìŠì–´ë²„ë ¸ì–´ìš”", "a": "ë¡œê·¸ì¸ í˜ì´ì§€ì—ì„œ 'ë¹„ë°€ë²ˆí˜¸ ì°¾ê¸°'ë¥¼ í´ë¦­í•˜ì„¸ìš”."},
                {"q": "í™˜ë¶ˆ ìš”ì²­ ë°©ë²•", "a": "ì„¤ì • > êµ¬ë… ê´€ë¦¬ > í™˜ë¶ˆ ìš”ì²­ì—ì„œ ì‹ ì²­ ê°€ëŠ¥í•©ë‹ˆë‹¤."},
                {"q": "ì•±ì´ ì‘ë™í•˜ì§€ ì•Šì•„ìš”", "a": "ì•±ì„ ì™„ì „íˆ ì¢…ë£Œ í›„ ì¬ì‹¤í–‰í•˜ê±°ë‚˜ ì—…ë°ì´íŠ¸ë¥¼ í™•ì¸í•˜ì„¸ìš”."}
            ],
            "policies": {
                "refund_policy": "êµ¬ë§¤ í›„ 7ì¼ ë‚´ 100% í™˜ë¶ˆ, 14ì¼ ë‚´ 50% í™˜ë¶ˆ",
                "support_hours": "í‰ì¼ 09:00-18:00, ì£¼ë§ 10:00-16:00"
            }
        }

    def create_ticket(self, customer_info: Dict, inquiry: str) -> str:
        """ê³ ê° í‹°ì¼“ ìƒì„±"""
        ticket_id = f"CS-{datetime.now().strftime('%Y%m%d%H%M%S')}"

        ticket = {
            "ticket_id": ticket_id,
            "customer_info": customer_info,
            "inquiry": inquiry,
            "status": "open",
            "priority": "normal",
            "created_at": datetime.now().isoformat(),
            "interactions": [],
            "resolution": None,
            "satisfaction_score": None
        }

        self.ticket_database[ticket_id] = ticket
        return ticket_id

    def process_customer_inquiry(self, customer_info: Dict, inquiry: str):
        """ê³ ê° ë¬¸ì˜ ì²˜ë¦¬ ë©”ì¸ í”Œë¡œìš°"""

        # í‹°ì¼“ ìƒì„±
        ticket_id = self.create_ticket(customer_info, inquiry)

        print(f"ğŸ« í‹°ì¼“ ìƒì„±: {ticket_id}")
        print(f"ğŸ‘¤ ê³ ê° ì •ë³´: {customer_info['name']} ({customer_info['email']})")
        print(f"ğŸ“ ë¬¸ì˜ ë‚´ìš©: {inquiry}")

        # 1ë‹¨ê³„: ì ‘ìˆ˜ ì²˜ë¦¬
        intake_msg = Msg(
            name="Customer",
            content=f"""ê³ ê° ì •ë³´:
            - ì´ë¦„: {customer_info['name']}
            - ì´ë©”ì¼: {customer_info['email']}
            - íšŒì› ë“±ê¸‰: {customer_info.get('tier', 'Standard')}

            ë¬¸ì˜ ë‚´ìš©: {inquiry}""",
            role="user"
        )

        intake_response = self.intake_agent(intake_msg)

        # ìƒí˜¸ì‘ìš© ê¸°ë¡
        self.ticket_database[ticket_id]["interactions"].append({
            "agent": "Intake_Specialist",
            "timestamp": datetime.now().isoformat(),
            "response": intake_response.content
        })

        print(f"\nğŸ“ ì ‘ìˆ˜ ì „ë¬¸ê°€: {intake_response.content}")

        # 2ë‹¨ê³„: ë¬¸ì˜ ìœ í˜• ë¶„ë¥˜ ë° ë¼ìš°íŒ…
        inquiry_type = self.classify_inquiry(inquiry)
        print(f"\nğŸ·ï¸ ë¬¸ì˜ ë¶„ë¥˜: {inquiry_type}")

        # ì „ë¬¸ê°€ì—ê²Œ ë¼ìš°íŒ…
        if inquiry_type == "technical":
            specialist = self.tech_support
            specialist_name = "ê¸°ìˆ  ì§€ì›íŒ€"
        elif inquiry_type == "billing":
            specialist = self.billing_support
            specialist_name = "ê²°ì œ ì§€ì›íŒ€"
        elif inquiry_type == "escalation":
            specialist = self.escalation_manager
            specialist_name = "ë§¤ë‹ˆì €"
        else:
            specialist = self.intake_agent
            specialist_name = "ì¼ë°˜ ìƒë‹´íŒ€"

        # ì „ë¬¸ê°€ ì‘ë‹µ
        specialist_msg = Msg(
            name="Intake_Specialist",
            content=f"""ì ‘ìˆ˜ ë‚´ìš©: {intake_response.content}

            ê³ ê° ì›ë³¸ ë¬¸ì˜: {inquiry}

            ì „ë¬¸ì ì¸ í•´ê²°ì±…ì„ ì œê³µí•´ì£¼ì„¸ìš”.""",
            role="assistant"
        )

        specialist_response = specialist(specialist_msg)

        # ìƒí˜¸ì‘ìš© ê¸°ë¡
        self.ticket_database[ticket_id]["interactions"].append({
            "agent": specialist_name,
            "timestamp": datetime.now().isoformat(),
            "response": specialist_response.content
        })

        print(f"\nğŸ‘¨â€ğŸ’¼ {specialist_name}: {specialist_response.content}")

        # 3ë‹¨ê³„: í’ˆì§ˆ ë³´ì¦ ê²€í† 
        qa_msg = Msg(
            name="Service_Team",
            content=f"""ì„œë¹„ìŠ¤ í’ˆì§ˆ ê²€í†  ìš”ì²­:

            ê³ ê° ë¬¸ì˜: {inquiry}
            ì ‘ìˆ˜íŒ€ ì‘ë‹µ: {intake_response.content}
            {specialist_name} ì‘ë‹µ: {specialist_response.content}

            ì„œë¹„ìŠ¤ í’ˆì§ˆì„ í‰ê°€í•˜ê³  ê°œì„ ì ì„ ì œì•ˆí•´ì£¼ì„¸ìš”.""",
            role="assistant"
        )

        qa_review = self.qa_agent(qa_msg)

        # ìµœì¢… í‹°ì¼“ ì—…ë°ì´íŠ¸
        self.ticket_database[ticket_id].update({
            "status": "resolved",
            "resolution": specialist_response.content,
            "qa_review": qa_review.content,
            "resolved_at": datetime.now().isoformat()
        })

        print(f"\nğŸ” í’ˆì§ˆ ë³´ì¦ ê²€í† : {qa_review.content}")

        # ê²°ê³¼ ë°˜í™˜
        return {
            "ticket_id": ticket_id,
            "inquiry_type": inquiry_type,
            "routed_to": specialist_name,
            "intake_response": intake_response.content,
            "specialist_response": specialist_response.content,
            "qa_review": qa_review.content,
            "status": "resolved"
        }

    def classify_inquiry(self, inquiry: str) -> str:
        """ë¬¸ì˜ ìœ í˜• ìë™ ë¶„ë¥˜"""
        inquiry_lower = inquiry.lower()

        # ê¸°ìˆ  ë¬¸ì˜
        tech_keywords = ["ì˜¤ë¥˜", "ë²„ê·¸", "ì‘ë™í•˜ì§€", "ì„¤ì¹˜", "ì—…ë°ì´íŠ¸", "ëŠë ¤", "ì¶©ëŒ"]
        if any(keyword in inquiry_lower for keyword in tech_keywords):
            return "technical"

        # ê²°ì œ ë¬¸ì˜
        billing_keywords = ["ê²°ì œ", "í™˜ë¶ˆ", "ìš”ê¸ˆ", "êµ¬ë…", "ì¹´ë“œ", "ê²°ì œì‹¤íŒ¨", "ì²­êµ¬"]
        if any(keyword in inquiry_lower for keyword in billing_keywords):
            return "billing"

        # ë¶ˆë§Œ ë° ì—ìŠ¤ì»¬ë ˆì´ì…˜
        escalation_keywords = ["ë¶ˆë§Œ", "í™”ë‚˜", "ìµœì•…", "ì†Œì†¡", "í•´ì§€", "ë§¤ë‹ˆì €"]
        if any(keyword in inquiry_lower for keyword in escalation_keywords):
            return "escalation"

        return "general"

    def get_service_analytics(self):
        """ì„œë¹„ìŠ¤ ë¶„ì„ ëŒ€ì‹œë³´ë“œ"""
        if not self.ticket_database:
            return "í‹°ì¼“ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."

        total_tickets = len(self.ticket_database)
        resolved_tickets = sum(1 for t in self.ticket_database.values() if t["status"] == "resolved")

        # ë¬¸ì˜ ìœ í˜•ë³„ í†µê³„
        inquiry_types = {}
        for ticket in self.ticket_database.values():
            inquiry_type = self.classify_inquiry(ticket["inquiry"])
            inquiry_types[inquiry_type] = inquiry_types.get(inquiry_type, 0) + 1

        analytics = f"""
ğŸ“Š ê³ ê° ì„œë¹„ìŠ¤ ë¶„ì„ ëŒ€ì‹œë³´ë“œ
================================

ğŸ“ˆ ì „ì²´ í†µê³„:
- ì´ í‹°ì¼“ ìˆ˜: {total_tickets}
- í•´ê²°ëœ í‹°ì¼“: {resolved_tickets}
- í•´ê²°ë¥ : {(resolved_tickets/total_tickets*100):.1f}%

ğŸ“‹ ë¬¸ì˜ ìœ í˜•ë³„ ë¶„í¬:"""

        for inquiry_type, count in inquiry_types.items():
            percentage = (count / total_tickets * 100)
            analytics += f"\n- {inquiry_type}: {count}ê±´ ({percentage:.1f}%)"

        return analytics

# ì‚¬ìš© ì˜ˆì œ ë° ì‹œì—°
def demonstrate_customer_service():
    """ê³ ê° ì„œë¹„ìŠ¤ ì‹œìŠ¤í…œ ì‹œì—°"""

    cs_system = SmartCustomerServiceSystem()

    # ë‹¤ì–‘í•œ ê³ ê° ë¬¸ì˜ ì‹œë®¬ë ˆì´ì…˜
    test_cases = [
        {
            "customer_info": {
                "name": "ê¹€ì² ìˆ˜",
                "email": "kim@example.com",
                "tier": "Premium"
            },
            "inquiry": "ì•±ì´ ê³„ì† ì˜¤ë¥˜ê°€ ë‚˜ë©´ì„œ ì‚¬ìš©í•  ìˆ˜ ì—†ì–´ìš”. ë¡œê·¸ì¸ë„ ì•ˆ ë˜ê³  ë°ì´í„°ë„ ì‚¬ë¼ì§„ ê²ƒ ê°™ìŠµë‹ˆë‹¤."
        },
        {
            "customer_info": {
                "name": "ì´ì˜í¬",
                "email": "lee@example.com",
                "tier": "Standard"
            },
            "inquiry": "ì´ë²ˆ ë‹¬ ê²°ì œê°€ ë‘ ë²ˆ ë˜ì—ˆëŠ”ë° í™˜ë¶ˆ ë°›ì„ ìˆ˜ ìˆë‚˜ìš”? ì¹´ë“œ ëª…ì„¸ì„œë¥¼ í™•ì¸í•´ë³´ë‹ˆ ì¤‘ë³µ ê²°ì œëœ ê²ƒ ê°™ìŠµë‹ˆë‹¤."
        },
        {
            "customer_info": {
                "name": "ë°•ë¯¼ìˆ˜",
                "email": "park@example.com",
                "tier": "Basic"
            },
            "inquiry": "ì„œë¹„ìŠ¤ê°€ ë„ˆë¬´ ë¶ˆì¹œì ˆí•˜ê³  ë¬¸ì œê°€ ë§ì•„ìš”. ë§¤ë‹ˆì €ì™€ í†µí™”í•˜ê³  ì‹¶ìŠµë‹ˆë‹¤. êµ¬ë… í•´ì§€ë„ ê³ ë ¤ ì¤‘ì…ë‹ˆë‹¤."
        }
    ]

    print("ğŸ­ ìŠ¤ë§ˆíŠ¸ ê³ ê° ì„œë¹„ìŠ¤ ì‹œìŠ¤í…œ ì‹œì—°")
    print("="*50)

    for i, test_case in enumerate(test_cases, 1):
        print(f"\nğŸª ì‹œì—° #{i}")
        print("-" * 30)

        result = cs_system.process_customer_inquiry(
            test_case["customer_info"],
            test_case["inquiry"]
        )

        print(f"\nâœ… ì²˜ë¦¬ ì™„ë£Œ - í‹°ì¼“ ID: {result['ticket_id']}")
        print(f"ğŸ·ï¸ ë¶„ë¥˜: {result['inquiry_type']}")
        print(f"ğŸ‘¥ ë‹´ë‹¹: {result['routed_to']}")

        if i < len(test_cases):
            print("\n" + "="*50)

    # ë¶„ì„ ëŒ€ì‹œë³´ë“œ ì¶œë ¥
    print("\n" + cs_system.get_service_analytics())

# ì‹œì—° ì‹¤í–‰
if __name__ == "__main__":
    demonstrate_customer_service()
```

## 5.2. ì°½ì‘ ì½˜í…ì¸  ì œì‘ ìŠ¤íŠœë””ì˜¤

```python
import agentscope
from agentscope.agents import DialogAgent
from agentscope.pipeline import sequential_pipeline
from agentscope.message import Msg
from agentscope.tools import write_text_file
import json
from datetime import datetime

class CreativeContentStudio:
    def __init__(self):
        self.setup_creative_team()

    def setup_creative_team(self):
        """ì°½ì‘íŒ€ ì—ì´ì „íŠ¸ë“¤ ì„¤ì •"""

        model_configs = [
            {
                "config_name": "creative_config",
                "model_type": "openai_chat",
                "model": "gpt-4o",
                "api_key": "your-openai-api-key"
            }
        ]

        agentscope.init(
            model_configs=model_configs,
            project="creative_content_studio"
        )

        # ì•„ì´ë””ì–´ ê¸°íšì
        self.ideator = DialogAgent(
            name="Creative_Ideator",
            model_config_name="creative_config",
            sys_prompt="""ë‹¹ì‹ ì€ ì°½ì˜ì  ì•„ì´ë””ì–´ ê¸°íšìì…ë‹ˆë‹¤.

            ì „ë¬¸ ë¶„ì•¼:
            1. íŠ¸ë Œë“œ ë¶„ì„ ë° ì¸ì‚¬ì´íŠ¸ ë„ì¶œ
            2. ë…ì°½ì ì´ê³  ë§¤ë ¥ì ì¸ ì•„ì´ë””ì–´ ë°œêµ´
            3. íƒ€ê²Ÿ ì˜¤ë””ì–¸ìŠ¤ ë¶„ì„
            4. ì½˜í…ì¸  ì»¨ì…‰ ê°œë°œ

            í•­ìƒ ì°¸ì‹ í•˜ê³  ì‹¤í˜„ ê°€ëŠ¥í•œ ì•„ì´ë””ì–´ë¥¼ ì œì•ˆí•˜ì„¸ìš”."""
        )

        # ìŠ¤í† ë¦¬í…”ëŸ¬
        self.storyteller = DialogAgent(
            name="Master_Storyteller",
            model_config_name="creative_config",
            sys_prompt="""ë‹¹ì‹ ì€ ë§ˆìŠ¤í„° ìŠ¤í† ë¦¬í…”ëŸ¬ì…ë‹ˆë‹¤.

            í•µì‹¬ ëŠ¥ë ¥:
            1. ê°ë™ì ì´ê³  ëª°ì…ë„ ë†’ì€ ìŠ¤í† ë¦¬ êµ¬ì„±
            2. ìºë¦­í„° ê°œë°œ ë° ì„œì‚¬ êµ¬ì¡° ì„¤ê³„
            3. ë‹¤ì–‘í•œ ì¥ë¥´ì™€ í†¤ì•¤ë§¤ë„ˆ êµ¬ì‚¬
            4. ë…ì ê°ì • ëª°ì… ìœ ë„

            ì¸ê°„ì˜ ë§ˆìŒì„ ì›€ì§ì´ëŠ” ìŠ¤í† ë¦¬ë¥¼ ë§Œë“œì„¸ìš”."""
        )

        # ì¹´í”¼ë¼ì´í„°
        self.copywriter = DialogAgent(
            name="Expert_Copywriter",
            model_config_name="creative_config",
            sys_prompt="""ë‹¹ì‹ ì€ ì „ë¬¸ ì¹´í”¼ë¼ì´í„°ì…ë‹ˆë‹¤.

            ì „ë¬¸ì„±:
            1. ë¸Œëœë“œ ë©”ì‹œì§€ ì „ë‹¬
            2. ì„¤ë“ë ¥ ìˆëŠ” ì¹´í”¼ ì‘ì„±
            3. íƒ€ê²Ÿë³„ í†¤ì•¤ë§¤ë„ˆ ìµœì í™”
            4. ì•¡ì…˜ ìœ ë„ ë° ì „í™˜ ìµœì í™”

            ê¸°ì–µì— ë‚¨ê³  í–‰ë™ì„ ì´ë„ëŠ” ì¹´í”¼ë¥¼ ì‘ì„±í•˜ì„¸ìš”."""
        )

        # ë¹„ì£¼ì–¼ ê¸°íšì
        self.visual_planner = DialogAgent(
            name="Visual_Planner",
            model_config_name="creative_config",
            sys_prompt="""ë‹¹ì‹ ì€ ë¹„ì£¼ì–¼ ê¸°íš ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

            ì „ë¬¸ ì˜ì—­:
            1. ì‹œê°ì  ì½˜ì…‰íŠ¸ ê°œë°œ
            2. ìƒ‰ìƒ, ë ˆì´ì•„ì›ƒ, íƒ€ì´í¬ê·¸ë˜í”¼ ê¸°íš
            3. ë¸Œëœë“œ ì•„ì´ë´í‹°í‹° êµ¬í˜„
            4. ë©€í‹°ë¯¸ë””ì–´ ì½˜í…ì¸  ì„¤ê³„

            ì‹œê°ì ìœ¼ë¡œ ì„íŒ©íŠ¸ìˆëŠ” ì½˜í…ì¸ ë¥¼ ê¸°íší•˜ì„¸ìš”."""
        )

        # ë§ˆì¼€íŒ… ì „ëµê°€
        self.marketing_strategist = DialogAgent(
            name="Marketing_Strategist",
            model_config_name="creative_config",
            sys_prompt="""ë‹¹ì‹ ì€ ë§ˆì¼€íŒ… ì „ëµ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

            í•µì‹¬ ì—­ëŸ‰:
            1. ì‹œì¥ ë¶„ì„ ë° ê²½ìŸì‚¬ ë²¤ì¹˜ë§ˆí‚¹
            2. íƒ€ê²Ÿ ì„¸ë¶„í™” ë° í˜ë¥´ì†Œë‚˜ ì„¤ì •
            3. ì±„ë„ë³„ ìµœì  ì „ëµ ìˆ˜ë¦½
            4. ì„±ê³¼ ì¸¡ì • ì§€í‘œ ì„¤ê³„

            íš¨ê³¼ì ì¸ ë§ˆì¼€íŒ… ì „ëµì„ ì œì‹œí•˜ì„¸ìš”."""
        )

        # í’ˆì§ˆ ê´€ë¦¬ì
        self.quality_controller = DialogAgent(
            name="Quality_Controller",
            model_config_name="creative_config",
            sys_prompt="""ë‹¹ì‹ ì€ ì½˜í…ì¸  í’ˆì§ˆ ê´€ë¦¬ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

            ê²€í†  í•­ëª©:
            1. ì½˜í…ì¸  ì¼ê´€ì„± ë° í’ˆì§ˆ í‰ê°€
            2. ë¸Œëœë“œ ê°€ì´ë“œë¼ì¸ ì¤€ìˆ˜ í™•ì¸
            3. ë²•ì /ìœ¤ë¦¬ì  ì´ìŠˆ ê²€í† 
            4. ìµœì¢… ê°œì„ ì•ˆ ì œì‹œ

            ê°ê´€ì ì´ê³  ê±´ì„¤ì ì¸ í”¼ë“œë°±ì„ ì œê³µí•˜ì„¸ìš”."""
        )

    def create_campaign(self, brief: Dict):
        """ìº í˜ì¸ ì œì‘ ì›Œí¬í”Œë¡œìš°"""

        print(f"ğŸ¬ ìº í˜ì¸ ì œì‘ ì‹œì‘: {brief['campaign_name']}")
        print(f"ğŸ¯ ëª©ì : {brief['objective']}")
        print(f"ğŸ‘¥ íƒ€ê²Ÿ: {brief['target_audience']}")
        print(f"ğŸ“… ê¸°ê°„: {brief.get('duration', 'ë¯¸ì •')}")

        # 1ë‹¨ê³„: ì•„ì´ë””ì–´ ê¸°íš
        print(f"\n{'='*50}")
        print("1ë‹¨ê³„: ì•„ì´ë””ì–´ ê¸°íš")
        print("="*50)

        ideation_msg = Msg(
            name="Client",
            content=f"""ìº í˜ì¸ ë¸Œë¦¬í”„:

            ìº í˜ì¸ëª…: {brief['campaign_name']}
            ëª©ì : {brief['objective']}
            íƒ€ê²Ÿ ì˜¤ë””ì–¸ìŠ¤: {brief['target_audience']}
            ì˜ˆì‚°: {brief.get('budget', 'í˜‘ì˜')}
            ì±„ë„: {brief.get('channels', 'ë©€í‹°ì±„ë„')}
            í•µì‹¬ ë©”ì‹œì§€: {brief.get('key_message', 'ë¯¸ì •')}

            ì°½ì˜ì ì´ê³  ì‹¤í˜„ ê°€ëŠ¥í•œ ìº í˜ì¸ ì•„ì´ë””ì–´ë¥¼ ì œì•ˆí•´ì£¼ì„¸ìš”.""",
            role="user"
        )

        creative_concept = self.ideator(ideation_msg)
        print(f"ğŸ’¡ ê¸°íš ì•„ì´ë””ì–´:\n{creative_concept.content}")

        # 2ë‹¨ê³„: ìŠ¤í† ë¦¬í…”ë§
        print(f"\n{'='*50}")
        print("2ë‹¨ê³„: ìŠ¤í† ë¦¬í…”ë§")
        print("="*50)

        story_msg = Msg(
            name="Creative_Ideator",
            content=f"ì°½ì˜ì  ì»¨ì…‰: {creative_concept.content}\n\n"
                   f"ì´ ì»¨ì…‰ì„ ë°”íƒ•ìœ¼ë¡œ {brief['target_audience']}ì—ê²Œ ê°ë™ì„ ì£¼ëŠ” "
                   f"ìŠ¤í† ë¦¬ë¥¼ ê°œë°œí•´ì£¼ì„¸ìš”. ë¸Œëœë“œ ë©”ì‹œì§€ '{brief.get('key_message', '')}'ë¥¼ "
                   f"ìì—°ìŠ¤ëŸ½ê²Œ ë…¹ì—¬ë‚´ì„¸ìš”.",
            role="assistant"
        )

        story_concept = self.storyteller(story_msg)
        print(f"ğŸ“– ìŠ¤í† ë¦¬ ì»¨ì…‰:\n{story_concept.content}")

        # 3ë‹¨ê³„: ì¹´í”¼ ì‘ì„±
        print(f"\n{'='*50}")
        print("3ë‹¨ê³„: ì¹´í”¼ ì‘ì„±")
        print("="*50)

        copy_msg = Msg(
            name="Master_Storyteller",
            content=f"ìŠ¤í† ë¦¬ ì»¨ì…‰: {story_concept.content}\n\n"
                   f"ì´ ìŠ¤í† ë¦¬ë¥¼ ë°”íƒ•ìœ¼ë¡œ {brief['target_audience']}ë¥¼ ìœ„í•œ "
                   f"ë§¤ë ¥ì ì¸ ì¹´í”¼ë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”. ë‹¤ìŒ ìš”ì†Œë¥¼ í¬í•¨í•˜ì„¸ìš”:\n"
                   f"- ë©”ì¸ í—¤ë“œë¼ì¸\n"
                   f"- ì„œë¸Œ í—¤ë“œë¼ì¸\n"
                   f"- ë³¸ë¬¸ ì¹´í”¼\n"
                   f"- CTA (Call to Action)",
            role="assistant"
        )

        copy_content = self.copywriter(copy_msg)
        print(f"âœï¸ ì¹´í”¼ ì½˜í…ì¸ :\n{copy_content.content}")

        # 4ë‹¨ê³„: ë¹„ì£¼ì–¼ ê¸°íš
        print(f"\n{'='*50}")
        print("4ë‹¨ê³„: ë¹„ì£¼ì–¼ ê¸°íš")
        print("="*50)

        visual_msg = Msg(
            name="Expert_Copywriter",
            content=f"ì¹´í”¼ ì½˜í…ì¸ : {copy_content.content}\n\n"
                   f"ìŠ¤í† ë¦¬: {story_concept.content}\n\n"
                   f"ì´ ì½˜í…ì¸ ë¥¼ ë’·ë°›ì¹¨í•˜ëŠ” ë¹„ì£¼ì–¼ ì½˜ì…‰íŠ¸ë¥¼ ê¸°íší•´ì£¼ì„¸ìš”:\n"
                   f"- ì „ì²´ì ì¸ ë¹„ì£¼ì–¼ í†¤ì•¤ë§¤ë„ˆ\n"
                   f"- ìƒ‰ìƒ íŒ”ë ˆíŠ¸ ì œì•ˆ\n"
                   f"- ë ˆì´ì•„ì›ƒ êµ¬ì„±ì•ˆ\n"
                   f"- í•µì‹¬ ë¹„ì£¼ì–¼ ìš”ì†Œ\n"
                   f"- ì±„ë„ë³„ ë¹„ì£¼ì–¼ ì ìš© ë°©ì•ˆ",
            role="assistant"
        )

        visual_concept = self.visual_planner(visual_msg)
        print(f"ğŸ¨ ë¹„ì£¼ì–¼ ê¸°íš:\n{visual_concept.content}")

        # 5ë‹¨ê³„: ë§ˆì¼€íŒ… ì „ëµ
        print(f"\n{'='*50}")
        print("5ë‹¨ê³„: ë§ˆì¼€íŒ… ì „ëµ")
        print("="*50)

        marketing_msg = Msg(
            name="Visual_Planner",
            content=f"""ìº í˜ì¸ ìš”ì†Œ í†µí•©:

            ì°½ì˜ ì»¨ì…‰: {creative_concept.content}

            ìŠ¤í† ë¦¬: {story_concept.content}

            ì¹´í”¼: {copy_content.content}

            ë¹„ì£¼ì–¼: {visual_concept.content}

            ì´ë¥¼ ë°”íƒ•ìœ¼ë¡œ íš¨ê³¼ì ì¸ ë§ˆì¼€íŒ… ì „ëµì„ ìˆ˜ë¦½í•´ì£¼ì„¸ìš”:
            - íƒ€ê²Ÿ ì„¸ë¶„í™” ì „ëµ
            - ì±„ë„ë³„ ì‹¤í–‰ ê³„íš
            - ë¡ ì¹­ ì¼ì • ë° ë‹¨ê³„
            - ì„±ê³¼ ì¸¡ì • KPI
            - ì˜ˆì‚° ë°°ë¶„ ì œì•ˆ""",
            role="assistant"
        )

        marketing_strategy = self.marketing_strategist(marketing_msg)
        print(f"ğŸ“ˆ ë§ˆì¼€íŒ… ì „ëµ:\n{marketing_strategy.content}")

        # 6ë‹¨ê³„: í’ˆì§ˆ ê´€ë¦¬
        print(f"\n{'='*50}")
        print("6ë‹¨ê³„: í’ˆì§ˆ ê´€ë¦¬")
        print("="*50)

        qc_msg = Msg(
            name="Marketing_Strategist",
            content=f"""ìº í˜ì¸ ì „ì²´ ê²€í† :

            [ì›ë³¸ ë¸Œë¦¬í”„]
            {json.dumps(brief, ensure_ascii=False, indent=2)}

            [ì œì‘ ê²°ê³¼ë¬¼]
            ì•„ì´ë””ì–´: {creative_concept.content}

            ìŠ¤í† ë¦¬: {story_concept.content}

            ì¹´í”¼: {copy_content.content}

            ë¹„ì£¼ì–¼: {visual_concept.content}

            ë§ˆì¼€íŒ… ì „ëµ: {marketing_strategy.content}

            ì „ì²´ ìº í˜ì¸ì˜ í’ˆì§ˆ, ì¼ê´€ì„±, ì‹¤í˜„ ê°€ëŠ¥ì„±ì„ ê²€í† í•˜ê³ 
            ê°œì„ ì ì„ ì œì•ˆí•´ì£¼ì„¸ìš”.""",
            role="assistant"
        )

        quality_review = self.quality_controller(qc_msg)
        print(f"ğŸ” í’ˆì§ˆ ê²€í† :\n{quality_review.content}")

        # ìµœì¢… ê²°ê³¼ë¬¼ êµ¬ì„±
        campaign_package = {
            "campaign_info": brief,
            "creative_concept": creative_concept.content,
            "story_concept": story_concept.content,
            "copy_content": copy_content.content,
            "visual_concept": visual_concept.content,
            "marketing_strategy": marketing_strategy.content,
            "quality_review": quality_review.content,
            "created_at": datetime.now().isoformat()
        }

        # ê²°ê³¼ë¬¼ íŒŒì¼ ì €ì¥
        filename = f"campaign_{brief['campaign_name'].replace(' ', '_')}_{datetime.now().strftime('%Y%m%d')}.json"
        write_text_file(filename, json.dumps(campaign_package, ensure_ascii=False, indent=2))

        print(f"\nğŸ‰ ìº í˜ì¸ ì œì‘ ì™„ë£Œ!")
        print(f"ğŸ“ ê²°ê³¼ë¬¼ ì €ì¥: {filename}")

        return campaign_package

# ì‚¬ìš© ì˜ˆì œ
def demo_creative_studio():
    """ì°½ì‘ ìŠ¤íŠœë””ì˜¤ ë°ëª¨"""

    studio = CreativeContentStudio()

    # ìº í˜ì¸ ë¸Œë¦¬í”„ ì˜ˆì œ
    campaign_brief = {
        "campaign_name": "ì§€ì† ê°€ëŠ¥í•œ ë¯¸ë˜ í”„ë¡œì íŠ¸",
        "objective": "í™˜ê²½ ë³´í˜¸ì— ëŒ€í•œ ì¸ì‹ ì œê³  ë° ì¹œí™˜ê²½ ì œí’ˆ êµ¬ë§¤ ìœ ë„",
        "target_audience": "20-40ëŒ€ í™˜ê²½ ì˜ì‹ì´ ìˆëŠ” ë„ì‹œ ê±°ì£¼ì",
        "budget": "5ì–µì›",
        "duration": "3ê°œì›”",
        "channels": ["ì†Œì…œë¯¸ë””ì–´", "OOH", "ë””ì§€í„¸ ê´‘ê³ ", "ì´ë²¤íŠ¸"],
        "key_message": "ì‘ì€ ì„ íƒì´ ë§Œë“œëŠ” í° ë³€í™”"
    }

    print("ğŸ­ ì°½ì‘ ì½˜í…ì¸  ìŠ¤íŠœë””ì˜¤ ë°ëª¨")
    print("="*60)

    # ìº í˜ì¸ ì œì‘ ì‹¤í–‰
    result = studio.create_campaign(campaign_brief)

    print("\nğŸ† ì œì‘ ì™„ë£Œ ìš”ì•½")
    print("="*30)
    print(f"ìº í˜ì¸ëª…: {result['campaign_info']['campaign_name']}")
    print(f"ì œì‘ì¼: {result['created_at']}")
    print("ëª¨ë“  ë‹¨ê³„ ì™„ë£Œ: âœ…")

# ë°ëª¨ ì‹¤í–‰
if __name__ == "__main__":
    demo_creative_studio()
```

---

# 6. í”„ë¡œë•ì…˜ ë°°í¬

## 6.1. AgentScope Studio ì›¹ ì¸í„°í˜ì´ìŠ¤

```bash
# AgentScope Studio ì„¤ì¹˜ ë° ì‹¤í–‰
pip install agentscope-runtime

# ìŠ¤íŠœë””ì˜¤ ì„œë²„ ì‹¤í–‰
agentscope-studio --port 8080

# ë°±ê·¸ë¼ìš´ë“œ ì‹¤í–‰
nohup agentscope-studio --port 8080 --host 0.0.0.0 > studio.log 2>&1 &
```

## 6.2. FastAPI ì„œë²„ í†µí•©

```python
from fastapi import FastAPI, HTTPException, BackgroundTasks
from pydantic import BaseModel
import agentscope
from agentscope.agents import DialogAgent
from agentscope.message import Msg
import uvicorn
import asyncio
from typing import Dict, List, Optional

app = FastAPI(title="AgentScope API Server", version="1.0.0")

# ê¸€ë¡œë²Œ ë³€ìˆ˜
agents_registry = {}
active_sessions = {}

class AgentRequest(BaseModel):
    agent_name: str
    message: str
    session_id: Optional[str] = None
    context: Optional[Dict] = None

class AgentResponse(BaseModel):
    response: str
    agent_name: str
    session_id: str
    timestamp: str

class AgentConfig(BaseModel):
    name: str
    model_config_name: str
    sys_prompt: str
    description: Optional[str] = None

@app.on_event("startup")
async def startup_event():
    """ì„œë²„ ì‹œì‘ì‹œ ì´ˆê¸°í™”"""

    # ëª¨ë¸ ì„¤ì •
    model_configs = [
        {
            "config_name": "default_openai",
            "model_type": "openai_chat",
            "model": "gpt-4o-mini",
            "api_key": "your-openai-api-key"
        }
    ]

    # AgentScope ì´ˆê¸°í™”
    agentscope.init(
        model_configs=model_configs,
        project="agentscope_api_server"
    )

    # ê¸°ë³¸ ì—ì´ì „íŠ¸ë“¤ ìƒì„±
    default_agents = [
        {
            "name": "assistant",
            "model_config_name": "default_openai",
            "sys_prompt": "You are a helpful assistant.",
            "description": "General purpose assistant"
        },
        {
            "name": "analyst",
            "model_config_name": "default_openai",
            "sys_prompt": "You are a data analyst. Provide insights based on data.",
            "description": "Data analysis specialist"
        },
        {
            "name": "writer",
            "model_config_name": "default_openai",
            "sys_prompt": "You are a professional writer. Create engaging content.",
            "description": "Content writing specialist"
        }
    ]

    # ì—ì´ì „íŠ¸ ë“±ë¡
    for agent_config in default_agents:
        agent = DialogAgent(
            name=agent_config["name"],
            model_config_name=agent_config["model_config_name"],
            sys_prompt=agent_config["sys_prompt"]
        )
        agents_registry[agent_config["name"]] = agent

    print(f"âœ… AgentScope API ì„œë²„ ì‹œì‘ - {len(agents_registry)}ê°œ ì—ì´ì „íŠ¸ ë¡œë“œë¨")

@app.post("/chat", response_model=AgentResponse)
async def chat_with_agent(request: AgentRequest):
    """ì—ì´ì „íŠ¸ì™€ ì±„íŒ…"""

    try:
        # ì—ì´ì „íŠ¸ í™•ì¸
        if request.agent_name not in agents_registry:
            raise HTTPException(status_code=404, detail=f"Agent '{request.agent_name}' not found")

        agent = agents_registry[request.agent_name]

        # ë©”ì‹œì§€ ìƒì„±
        msg = Msg(
            name="User",
            content=request.message,
            role="user"
        )

        # ì—ì´ì „íŠ¸ ì‹¤í–‰
        response = agent(msg)

        # ì„¸ì…˜ ê´€ë¦¬
        session_id = request.session_id or f"session_{len(active_sessions)}"
        if session_id not in active_sessions:
            active_sessions[session_id] = []

        # ëŒ€í™” ì´ë ¥ ì €ì¥
        active_sessions[session_id].append({
            "user_message": request.message,
            "agent_response": response.content,
            "agent_name": request.agent_name,
            "timestamp": response.timestamp if hasattr(response, 'timestamp') else str(datetime.now())
        })

        return AgentResponse(
            response=response.content,
            agent_name=request.agent_name,
            session_id=session_id,
            timestamp=str(datetime.now())
        )

    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/create-agent")
async def create_agent(config: AgentConfig):
    """ë™ì  ì—ì´ì „íŠ¸ ìƒì„±"""

    try:
        if config.name in agents_registry:
            raise HTTPException(status_code=400, detail=f"Agent '{config.name}' already exists")

        # ìƒˆ ì—ì´ì „íŠ¸ ìƒì„±
        agent = DialogAgent(
            name=config.name,
            model_config_name=config.model_config_name,
            sys_prompt=config.sys_prompt
        )

        agents_registry[config.name] = agent

        return {
            "message": f"Agent '{config.name}' created successfully",
            "agent_count": len(agents_registry)
        }

    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/agents")
async def list_agents():
    """ë“±ë¡ëœ ì—ì´ì „íŠ¸ ëª©ë¡"""
    return {
        "agents": list(agents_registry.keys()),
        "total_count": len(agents_registry)
    }

@app.get("/sessions/{session_id}")
async def get_session_history(session_id: str):
    """ì„¸ì…˜ ëŒ€í™” ì´ë ¥ ì¡°íšŒ"""
    if session_id not in active_sessions:
        raise HTTPException(status_code=404, detail="Session not found")

    return {
        "session_id": session_id,
        "conversation_count": len(active_sessions[session_id]),
        "history": active_sessions[session_id]
    }

@app.delete("/sessions/{session_id}")
async def delete_session(session_id: str):
    """ì„¸ì…˜ ì‚­ì œ"""
    if session_id in active_sessions:
        del active_sessions[session_id]
        return {"message": f"Session '{session_id}' deleted"}
    else:
        raise HTTPException(status_code=404, detail="Session not found")

@app.get("/health")
async def health_check():
    """í—¬ìŠ¤ ì²´í¬"""
    return {
        "status": "healthy",
        "agent_count": len(agents_registry),
        "active_sessions": len(active_sessions),
        "framework": "AgentScope"
    }

if __name__ == "__main__":
    uvicorn.run(
        app,
        host="0.0.0.0",
        port=8000,
        log_level="info"
    )
```

## 6.3. Docker ì»¨í…Œì´ë„ˆ ë°°í¬

```dockerfile
# Dockerfile
FROM python:3.11-slim

# ì‘ì—… ë””ë ‰í† ë¦¬ ì„¤ì •
WORKDIR /app

# ì‹œìŠ¤í…œ ì˜ì¡´ì„± ì„¤ì¹˜
RUN apt-get update && apt-get install -y \
    gcc \
    g++ \
    curl \
    && rm -rf /var/lib/apt/lists/*

# Python ì˜ì¡´ì„± ì„¤ì¹˜
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# AgentScope ì„¤ì¹˜
RUN pip install agentscope agentscope-runtime

# ì• í”Œë¦¬ì¼€ì´ì…˜ ì½”ë“œ ë³µì‚¬
COPY . .

# í™˜ê²½ ë³€ìˆ˜
ENV PYTHONPATH=/app
ENV AGENTSCOPE_CACHE_DIR=/app/cache
ENV PORT=8000

# ë””ë ‰í† ë¦¬ ìƒì„±
RUN mkdir -p /app/logs /app/cache /app/data

# í¬íŠ¸ ë…¸ì¶œ
EXPOSE 8000 8080

# í—¬ìŠ¤ì²´í¬
HEALTHCHECK --interval=30s --timeout=30s --start-period=5s --retries=3 \
    CMD curl -f http://localhost:8000/health || exit 1

# ì‹œì‘ ìŠ¤í¬ë¦½íŠ¸
COPY start.sh /app/start.sh
RUN chmod +x /app/start.sh

CMD ["/app/start.sh"]
```

```bash
# start.sh
#!/bin/bash

echo "ğŸš€ AgentScope ì„œë²„ ì‹œì‘ ì¤‘..."

# í™˜ê²½ ë³€ìˆ˜ í™•ì¸
if [ -z "$OPENAI_API_KEY" ]; then
    echo "âš ï¸ WARNING: OPENAI_API_KEY not set"
fi

# ìºì‹œ ë””ë ‰í† ë¦¬ ê¶Œí•œ ì„¤ì •
chmod -R 755 /app/cache

# ë°±ê·¸ë¼ìš´ë“œì—ì„œ AgentScope Studio ì‹¤í–‰
echo "ğŸ¨ AgentScope Studio ì‹œì‘ (í¬íŠ¸ 8080)..."
agentscope-studio --port 8080 --host 0.0.0.0 > /app/logs/studio.log 2>&1 &

# API ì„œë²„ ì‹¤í–‰
echo "ğŸ”§ API ì„œë²„ ì‹œì‘ (í¬íŠ¸ 8000)..."
python main.py
```

```yaml
# docker-compose.yml
version: '3.8'

services:
  agentscope-api:
    build: .
    ports:
      - "8000:8000"  # API ì„œë²„
      - "8080:8080"  # AgentScope Studio
    environment:
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - ANTHROPIC_API_KEY=${ANTHROPIC_API_KEY}
      - GOOGLE_API_KEY=${GOOGLE_API_KEY}
      - AGENTSCOPE_CACHE_DIR=/app/cache
    volumes:
      - ./data:/app/data
      - ./logs:/app/logs
      - ./cache:/app/cache
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  redis:
    image: redis:7-alpine
    restart: unless-stopped
    volumes:
      - redis_data:/data

  postgres:
    image: postgres:15
    environment:
      - POSTGRES_DB=agentscope
      - POSTGRES_USER=agentscope
      - POSTGRES_PASSWORD=${DB_PASSWORD}
    volumes:
      - postgres_data:/var/lib/postgresql/data
    restart: unless-stopped

  nginx:
    image: nginx:alpine
    ports:
      - "80:80"
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf
    depends_on:
      - agentscope-api
    restart: unless-stopped

volumes:
  redis_data:
  postgres_data:
```

## 6.4. í´ë¼ìš°ë“œ ë°°í¬ (AWS/GCP/Azure)

```yaml
# kubernetes-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: agentscope-deployment
spec:
  replicas: 3
  selector:
    matchLabels:
      app: agentscope
  template:
    metadata:
      labels:
        app: agentscope
    spec:
      containers:
      - name: agentscope
        image: your-registry/agentscope:latest
        ports:
        - containerPort: 8000
        - containerPort: 8080
        env:
        - name: OPENAI_API_KEY
          valueFrom:
            secretKeyRef:
              name: api-keys
              key: openai-key
        resources:
          requests:
            memory: "1Gi"
            cpu: "500m"
          limits:
            memory: "2Gi"
            cpu: "1000m"
        livenessProbe:
          httpGet:
            path: /health
            port: 8000
          initialDelaySeconds: 30
          periodSeconds: 10

---
apiVersion: v1
kind: Service
metadata:
  name: agentscope-service
spec:
  selector:
    app: agentscope
  ports:
  - name: api
    port: 8000
    targetPort: 8000
  - name: studio
    port: 8080
    targetPort: 8080
  type: LoadBalancer
```

---

# 7. ëª¨ë²” ì‚¬ë¡€ ë° ìµœì í™”

## 7.1. ì„±ëŠ¥ ìµœì í™”

### 7.1.1. ë¹„ë™ê¸° ì²˜ë¦¬ ìµœì í™”

```python
import asyncio
import agentscope
from agentscope.agents import DialogAgent
from agentscope.message import Msg
from concurrent.futures import ThreadPoolExecutor
import time

class OptimizedAgentPool:
    def __init__(self, max_workers: int = 10):
        self.max_workers = max_workers
        self.executor = ThreadPoolExecutor(max_workers=max_workers)
        self.agents = {}
        self.setup_agents()

    def setup_agents(self):
        """ìµœì í™”ëœ ì—ì´ì „íŠ¸ í’€ ì„¤ì •"""

        model_configs = [
            {
                "config_name": "fast_model",
                "model_type": "openai_chat",
                "model": "gpt-4o-mini",  # ë¹ ë¥¸ ëª¨ë¸
                "api_key": "your-openai-api-key"
            },
            {
                "config_name": "smart_model",
                "model_type": "openai_chat",
                "model": "gpt-4o",  # ì„±ëŠ¥ ì¤‘ì‹œ ëª¨ë¸
                "api_key": "your-openai-api-key"
            }
        ]

        agentscope.init(
            model_configs=model_configs,
            project="optimized_agent_pool"
        )

        # ë¹ ë¥¸ ì‘ë‹µìš© ì—ì´ì „íŠ¸ë“¤
        for i in range(5):
            agent = DialogAgent(
                name=f"fast_agent_{i}",
                model_config_name="fast_model",
                sys_prompt="Provide quick, concise responses."
            )
            self.agents[f"fast_agent_{i}"] = agent

        # ë³µì¡í•œ ì‘ì—…ìš© ì—ì´ì „íŠ¸ë“¤
        for i in range(3):
            agent = DialogAgent(
                name=f"smart_agent_{i}",
                model_config_name="smart_model",
                sys_prompt="Provide detailed, thoughtful responses."
            )
            self.agents[f"smart_agent_{i}"] = agent

    async def process_batch_requests(self, requests: List[Dict]):
        """ë°°ì¹˜ ìš”ì²­ ë¹„ë™ê¸° ì²˜ë¦¬"""

        async def process_single_request(request):
            """ë‹¨ì¼ ìš”ì²­ ì²˜ë¦¬"""
            agent_type = request.get("agent_type", "fast")

            # ì ì ˆí•œ ì—ì´ì „íŠ¸ ì„ íƒ
            if agent_type == "fast":
                available_agents = [k for k in self.agents.keys() if k.startswith("fast_")]
            else:
                available_agents = [k for k in self.agents.keys() if k.startswith("smart_")]

            # ë¼ìš´ë“œ ë¡œë¹ˆ ë°©ì‹ìœ¼ë¡œ ì—ì´ì „íŠ¸ ì„ íƒ
            agent_name = available_agents[request["request_id"] % len(available_agents)]
            agent = self.agents[agent_name]

            # ë©”ì‹œì§€ ì²˜ë¦¬
            msg = Msg(
                name="User",
                content=request["message"],
                role="user"
            )

            start_time = time.time()
            response = agent(msg)
            processing_time = time.time() - start_time

            return {
                "request_id": request["request_id"],
                "agent_used": agent_name,
                "response": response.content,
                "processing_time": processing_time
            }

        # ëª¨ë“  ìš”ì²­ì„ ë³‘ë ¬ ì²˜ë¦¬
        tasks = [process_single_request(req) for req in requests]
        results = await asyncio.gather(*tasks, return_exceptions=True)

        return results

    async def smart_routing(self, requests: List[Dict]):
        """ì§€ëŠ¥í˜• ë¼ìš°íŒ… - ìš”ì²­ ë³µì¡ë„ì— ë”°ë¼ ì—ì´ì „íŠ¸ ì„ íƒ"""

        def analyze_complexity(message: str) -> str:
            """ë©”ì‹œì§€ ë³µì¡ë„ ë¶„ì„"""

            # ê°„ë‹¨í•œ íœ´ë¦¬ìŠ¤í‹± - ì‹¤ì œë¡œëŠ” ë” ì •êµí•œ ë¶„ì„ í•„ìš”
            if len(message.split()) > 50:
                return "smart"
            elif any(keyword in message.lower() for keyword in
                    ["analyze", "complex", "detailed", "explain", "research"]):
                return "smart"
            else:
                return "fast"

        # ìš”ì²­ë³„ ë³µì¡ë„ ë¶„ì„ ë° ì—ì´ì „íŠ¸ íƒ€ì… ì„¤ì •
        for req in requests:
            if "agent_type" not in req:
                req["agent_type"] = analyze_complexity(req["message"])

        return await self.process_batch_requests(requests)

# ì‚¬ìš© ì˜ˆì œ
async def performance_test():
    """ì„±ëŠ¥ í…ŒìŠ¤íŠ¸"""

    agent_pool = OptimizedAgentPool(max_workers=8)

    # í…ŒìŠ¤íŠ¸ ìš”ì²­ ìƒì„±
    test_requests = [
        {
            "request_id": i,
            "message": f"Simple question #{i}: What is AI?" if i % 2 == 0
                      else f"Complex analysis #{i}: Provide a detailed analysis of artificial intelligence trends, market impact, and future implications for businesses.",
            "user_id": f"user_{i % 3}"
        }
        for i in range(20)
    ]

    print(f"ğŸš€ ì²˜ë¦¬ ì‹œì‘: {len(test_requests)}ê°œ ìš”ì²­")
    start_time = time.time()

    # ë°°ì¹˜ ì²˜ë¦¬
    results = await agent_pool.smart_routing(test_requests)

    total_time = time.time() - start_time

    print(f"âœ… ì²˜ë¦¬ ì™„ë£Œ: {total_time:.2f}ì´ˆ")
    print(f"ğŸ“Š í‰ê·  ì²˜ë¦¬ ì‹œê°„: {total_time/len(test_requests):.2f}ì´ˆ/ìš”ì²­")

    # ê²°ê³¼ ë¶„ì„
    fast_count = sum(1 for r in results if "fast_agent" in r["agent_used"])
    smart_count = sum(1 for r in results if "smart_agent" in r["agent_used"])

    print(f"ğŸ”„ ì—ì´ì „íŠ¸ ì‚¬ìš© ë¶„í¬:")
    print(f"  - ë¹ ë¥¸ ì—ì´ì „íŠ¸: {fast_count}ê°œ")
    print(f"  - ìŠ¤ë§ˆíŠ¸ ì—ì´ì „íŠ¸: {smart_count}ê°œ")

# ì‹¤í–‰
if __name__ == "__main__":
    asyncio.run(performance_test())
```

### 7.1.2. ë©”ëª¨ë¦¬ ë° ìºì‹± ìµœì í™”

```python
import agentscope
from agentscope.agents import DialogAgent
from agentscope.message import Msg
import hashlib
import time
import json
from typing import Dict, Any, Optional
import sqlite3
import threading

class CachedAgentManager:
    def __init__(self, cache_size: int = 1000, cache_ttl: int = 3600):
        self.cache_size = cache_size
        self.cache_ttl = cache_ttl
        self.memory_cache = {}
        self.cache_stats = {"hits": 0, "misses": 0}
        self.lock = threading.Lock()

        # SQLite ê¸°ë°˜ ì˜êµ¬ ìºì‹œ
        self.setup_persistent_cache()
        self.setup_agents()

    def setup_persistent_cache(self):
        """ì˜êµ¬ ìºì‹œ ì„¤ì •"""
        self.db_connection = sqlite3.connect("agent_cache.db", check_same_thread=False)
        cursor = self.db_connection.cursor()

        cursor.execute('''
            CREATE TABLE IF NOT EXISTS agent_cache (
                cache_key TEXT PRIMARY KEY,
                agent_name TEXT,
                request_content TEXT,
                response_content TEXT,
                created_at REAL,
                access_count INTEGER DEFAULT 1
            )
        ''')

        # ì¸ë±ìŠ¤ ìƒì„±
        cursor.execute('''
            CREATE INDEX IF NOT EXISTS idx_agent_created
            ON agent_cache(agent_name, created_at)
        ''')

        self.db_connection.commit()

    def setup_agents(self):
        """ì—ì´ì „íŠ¸ ì„¤ì •"""
        model_configs = [
            {
                "config_name": "cached_config",
                "model_type": "openai_chat",
                "model": "gpt-4o-mini",
                "api_key": "your-openai-api-key"
            }
        ]

        agentscope.init(
            model_configs=model_configs,
            project="cached_agent_system"
        )

        self.agents = {
            "general": DialogAgent(
                name="general_agent",
                model_config_name="cached_config",
                sys_prompt="You are a helpful assistant."
            ),
            "analyst": DialogAgent(
                name="analyst_agent",
                model_config_name="cached_config",
                sys_prompt="You are a data analyst."
            )
        }

    def generate_cache_key(self, agent_name: str, message: str) -> str:
        """ìºì‹œ í‚¤ ìƒì„±"""
        content = f"{agent_name}:{message}"
        return hashlib.md5(content.encode()).hexdigest()

    def get_from_memory_cache(self, cache_key: str) -> Optional[str]:
        """ë©”ëª¨ë¦¬ ìºì‹œì—ì„œ ì¡°íšŒ"""
        with self.lock:
            if cache_key in self.memory_cache:
                entry = self.memory_cache[cache_key]

                # TTL í™•ì¸
                if time.time() - entry["timestamp"] < self.cache_ttl:
                    entry["access_count"] += 1
                    self.cache_stats["hits"] += 1
                    return entry["response"]
                else:
                    # ë§Œë£Œëœ í•­ëª© ì œê±°
                    del self.memory_cache[cache_key]

            return None

    def set_memory_cache(self, cache_key: str, response: str):
        """ë©”ëª¨ë¦¬ ìºì‹œì— ì €ì¥"""
        with self.lock:
            # ìºì‹œ í¬ê¸° ì œí•œ
            if len(self.memory_cache) >= self.cache_size:
                # LRU ë°©ì‹ìœ¼ë¡œ ì˜¤ë˜ëœ í•­ëª© ì œê±°
                oldest_key = min(
                    self.memory_cache.keys(),
                    key=lambda k: self.memory_cache[k]["timestamp"]
                )
                del self.memory_cache[oldest_key]

            self.memory_cache[cache_key] = {
                "response": response,
                "timestamp": time.time(),
                "access_count": 1
            }

    def get_from_persistent_cache(self, cache_key: str) -> Optional[str]:
        """ì˜êµ¬ ìºì‹œì—ì„œ ì¡°íšŒ"""
        cursor = self.db_connection.cursor()

        cursor.execute('''
            SELECT response_content, created_at, access_count
            FROM agent_cache
            WHERE cache_key = ?
        ''', (cache_key,))

        result = cursor.fetchone()

        if result:
            response_content, created_at, access_count = result

            # TTL í™•ì¸
            if time.time() - created_at < self.cache_ttl:
                # ì•¡ì„¸ìŠ¤ íšŸìˆ˜ ì—…ë°ì´íŠ¸
                cursor.execute('''
                    UPDATE agent_cache
                    SET access_count = access_count + 1
                    WHERE cache_key = ?
                ''', (cache_key,))
                self.db_connection.commit()

                self.cache_stats["hits"] += 1
                return response_content

        return None

    def set_persistent_cache(self, cache_key: str, agent_name: str,
                           request: str, response: str):
        """ì˜êµ¬ ìºì‹œì— ì €ì¥"""
        cursor = self.db_connection.cursor()

        cursor.execute('''
            INSERT OR REPLACE INTO agent_cache
            (cache_key, agent_name, request_content, response_content, created_at)
            VALUES (?, ?, ?, ?, ?)
        ''', (cache_key, agent_name, request, response, time.time()))

        self.db_connection.commit()

    def process_with_cache(self, agent_name: str, message: str) -> Dict[str, Any]:
        """ìºì‹œë¥¼ í™œìš©í•œ ì—ì´ì „íŠ¸ ì²˜ë¦¬"""

        cache_key = self.generate_cache_key(agent_name, message)
        start_time = time.time()

        # 1ë‹¨ê³„: ë©”ëª¨ë¦¬ ìºì‹œ í™•ì¸
        cached_response = self.get_from_memory_cache(cache_key)
        if cached_response:
            return {
                "response": cached_response,
                "cache_hit": "memory",
                "processing_time": time.time() - start_time,
                "agent_used": agent_name
            }

        # 2ë‹¨ê³„: ì˜êµ¬ ìºì‹œ í™•ì¸
        cached_response = self.get_from_persistent_cache(cache_key)
        if cached_response:
            # ë©”ëª¨ë¦¬ ìºì‹œì—ë„ ì €ì¥
            self.set_memory_cache(cache_key, cached_response)

            return {
                "response": cached_response,
                "cache_hit": "persistent",
                "processing_time": time.time() - start_time,
                "agent_used": agent_name
            }

        # 3ë‹¨ê³„: ì‹¤ì œ ì—ì´ì „íŠ¸ ì‹¤í–‰
        self.cache_stats["misses"] += 1

        if agent_name not in self.agents:
            raise ValueError(f"Unknown agent: {agent_name}")

        agent = self.agents[agent_name]
        msg = Msg(name="User", content=message, role="user")

        response = agent(msg)
        response_content = response.content

        # ì–‘ìª½ ìºì‹œì— ì €ì¥
        self.set_memory_cache(cache_key, response_content)
        self.set_persistent_cache(cache_key, agent_name, message, response_content)

        return {
            "response": response_content,
            "cache_hit": "none",
            "processing_time": time.time() - start_time,
            "agent_used": agent_name
        }

    def get_cache_stats(self) -> Dict[str, Any]:
        """ìºì‹œ í†µê³„ ì¡°íšŒ"""
        total_requests = self.cache_stats["hits"] + self.cache_stats["misses"]
        hit_rate = (self.cache_stats["hits"] / total_requests * 100) if total_requests > 0 else 0

        cursor = self.db_connection.cursor()
        cursor.execute("SELECT COUNT(*) FROM agent_cache")
        persistent_cache_size = cursor.fetchone()[0]

        return {
            "memory_cache_size": len(self.memory_cache),
            "persistent_cache_size": persistent_cache_size,
            "total_hits": self.cache_stats["hits"],
            "total_misses": self.cache_stats["misses"],
            "hit_rate_percent": round(hit_rate, 2),
            "cache_ttl_seconds": self.cache_ttl
        }

    def cleanup_expired_cache(self):
        """ë§Œë£Œëœ ìºì‹œ ì •ë¦¬"""
        current_time = time.time()

        # ë©”ëª¨ë¦¬ ìºì‹œ ì •ë¦¬
        with self.lock:
            expired_keys = [
                key for key, entry in self.memory_cache.items()
                if current_time - entry["timestamp"] > self.cache_ttl
            ]
            for key in expired_keys:
                del self.memory_cache[key]

        # ì˜êµ¬ ìºì‹œ ì •ë¦¬
        cursor = self.db_connection.cursor()
        cursor.execute('''
            DELETE FROM agent_cache
            WHERE created_at < ?
        ''', (current_time - self.cache_ttl,))
        self.db_connection.commit()

        print(f"ğŸ§¹ ìºì‹œ ì •ë¦¬ ì™„ë£Œ: ë©”ëª¨ë¦¬ {len(expired_keys)}ê°œ, "
              f"ì˜êµ¬ {cursor.rowcount}ê°œ í•­ëª© ì œê±°")

# ì‚¬ìš© ì˜ˆì œ ë° ë²¤ì¹˜ë§ˆí¬
def benchmark_cached_system():
    """ìºì‹œ ì‹œìŠ¤í…œ ë²¤ì¹˜ë§ˆí¬"""

    cached_manager = CachedAgentManager(cache_size=100, cache_ttl=1800)

    # í…ŒìŠ¤íŠ¸ ë©”ì‹œì§€ë“¤
    test_messages = [
        "What is artificial intelligence?",
        "Explain machine learning basics",
        "What are the benefits of AI?",
        "How does deep learning work?",
        "What is artificial intelligence?",  # ì¤‘ë³µ (ìºì‹œ íˆíŠ¸)
        "Explain machine learning basics",   # ì¤‘ë³µ (ìºì‹œ íˆíŠ¸)
    ]

    print("ğŸ ìºì‹œ ì‹œìŠ¤í…œ ë²¤ì¹˜ë§ˆí¬ ì‹œì‘")
    print("="*40)

    total_time = 0

    for i, message in enumerate(test_messages, 1):
        print(f"\nğŸ“ ìš”ì²­ #{i}: {message[:30]}...")

        result = cached_manager.process_with_cache("general", message)
        total_time += result["processing_time"]

        print(f"   â±ï¸ ì²˜ë¦¬ ì‹œê°„: {result['processing_time']:.3f}ì´ˆ")
        print(f"   ğŸ’¾ ìºì‹œ ìƒíƒœ: {result['cache_hit']}")
        print(f"   ğŸ“¤ ì‘ë‹µ ê¸¸ì´: {len(result['response'])}ì")

    print(f"\nğŸ“Š ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼")
    print("="*25)
    print(f"ì´ ì²˜ë¦¬ ì‹œê°„: {total_time:.3f}ì´ˆ")
    print(f"í‰ê·  ì²˜ë¦¬ ì‹œê°„: {total_time/len(test_messages):.3f}ì´ˆ")

    # ìºì‹œ í†µê³„ ì¶œë ¥
    stats = cached_manager.get_cache_stats()
    print(f"\nğŸ’¾ ìºì‹œ í†µê³„:")
    for key, value in stats.items():
        print(f"   {key}: {value}")

    # ìºì‹œ ì •ë¦¬
    cached_manager.cleanup_expired_cache()

# ì‹¤í–‰
if __name__ == "__main__":
    benchmark_cached_system()
```

---

# 8. íŠ¸ëŸ¬ë¸”ìŠˆíŒ…

## 8.1. ì¼ë°˜ì ì¸ ë¬¸ì œë“¤

### ë¬¸ì œ: AgentScope ì´ˆê¸°í™” ì‹¤íŒ¨
```python
# í•´ê²°ì±…: ì˜¬ë°”ë¥¸ ì´ˆê¸°í™” ìˆœì„œ
import agentscope

# âŒ ì˜ëª»ëœ ë°©ë²•
# agent = DialogAgent(...)  # ì´ˆê¸°í™” ì „ì— ìƒì„±

# âœ… ì˜¬ë°”ë¥¸ ë°©ë²•
model_configs = [...]
agentscope.init(model_configs=model_configs, project="my_project")
agent = DialogAgent(...)  # ì´ˆê¸°í™” í›„ì— ìƒì„±
```

### ë¬¸ì œ: ëª¨ë¸ ì„¤ì • ì˜¤ë¥˜
```python
# í•´ê²°ì±…: ì˜¬ë°”ë¥¸ ëª¨ë¸ ì„¤ì • í˜•ì‹
model_config = {
    "config_name": "unique_name",  # ê³ ìœ í•œ ì´ë¦„ í•„ìˆ˜
    "model_type": "openai_chat",   # ì •í™•í•œ íƒ€ì…ëª…
    "model": "gpt-4o-mini",        # ì˜¬ë°”ë¥¸ ëª¨ë¸ëª…
    "api_key": "sk-...",           # ìœ íš¨í•œ API í‚¤
    # ì¶”ê°€ ì„¤ì •ë“¤
    "temperature": 0.7,
    "max_tokens": 1000
}
```

### ë¬¸ì œ: ë¹„ë™ê¸° ì‹¤í–‰ ë¬¸ì œ
```python
# í•´ê²°ì±…: ì˜¬ë°”ë¥¸ ë¹„ë™ê¸° íŒ¨í„´
import asyncio

async def correct_async_usage():
    # ë¹„ë™ê¸° ë©”ì„œë“œ ì‚¬ìš©
    result = await agent.async_run(message)
    return result

# ì‹¤í–‰
result = asyncio.run(correct_async_usage())
```

## 8.2. ë””ë²„ê¹… ë° ë¡œê¹…

```python
import logging
import agentscope
from agentscope.agents import DialogAgent
from agentscope.message import Msg
import json

# ìƒì„¸ ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.DEBUG,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('agentscope_debug.log'),
        logging.StreamHandler()
    ]
)

class DebuggingAgent:
    def __init__(self, agent_name: str):
        self.agent_name = agent_name
        self.logger = logging.getLogger(f"AgentScope.{agent_name}")
        self.setup_agent()

    def setup_agent(self):
        """ë””ë²„ê¹…ì´ í™œì„±í™”ëœ ì—ì´ì „íŠ¸ ì„¤ì •"""

        model_configs = [
            {
                "config_name": "debug_config",
                "model_type": "openai_chat",
                "model": "gpt-4o-mini",
                "api_key": "your-openai-api-key"
            }
        ]

        agentscope.init(
            model_configs=model_configs,
            project="debugging_test",
            logger_level="DEBUG"  # ìƒì„¸ ë¡œê¹…
        )

        self.agent = DialogAgent(
            name=self.agent_name,
            model_config_name="debug_config",
            sys_prompt="You are a helpful assistant with debugging enabled."
        )

    def debug_run(self, message: str):
        """ë””ë²„ê¹… ì •ë³´ì™€ í•¨ê»˜ ì—ì´ì „íŠ¸ ì‹¤í–‰"""

        self.logger.info(f"=== ë””ë²„ê¹… ì‹œì‘ ===")
        self.logger.info(f"Agent: {self.agent_name}")
        self.logger.info(f"Input: {message}")

        try:
            # ë©”ì‹œì§€ ìƒì„± ë¡œê·¸
            msg = Msg(name="User", content=message, role="user")
            self.logger.debug(f"Message object created: {msg}")

            # ì—ì´ì „íŠ¸ ì‹¤í–‰
            self.logger.info("ì—ì´ì „íŠ¸ ì‹¤í–‰ ì‹œì‘...")
            response = self.agent(msg)

            # ì‘ë‹µ ë¡œê·¸
            self.logger.info(f"Response received: {len(response.content)} characters")
            self.logger.debug(f"Full response: {response.content}")

            # ë©”íƒ€ë°ì´í„° ë¡œê·¸ (ìˆëŠ” ê²½ìš°)
            if hasattr(response, 'metadata'):
                self.logger.debug(f"Response metadata: {response.metadata}")

            return response

        except Exception as e:
            self.logger.error(f"ì—ì´ì „íŠ¸ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {str(e)}")
            self.logger.exception("ìƒì„¸ ì˜¤ë¥˜ ì •ë³´:")
            raise

        finally:
            self.logger.info("=== ë””ë²„ê¹… ì™„ë£Œ ===")

# ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ë„êµ¬
class PerformanceMonitor:
    def __init__(self):
        self.metrics = {
            "total_requests": 0,
            "total_response_time": 0,
            "error_count": 0,
            "requests_by_agent": {},
            "average_response_length": 0
        }

    def track_request(self, agent_name: str, processing_time: float,
                     response_length: int, success: bool = True):
        """ìš”ì²­ ë©”íŠ¸ë¦­ ì¶”ì """

        self.metrics["total_requests"] += 1
        self.metrics["total_response_time"] += processing_time

        if not success:
            self.metrics["error_count"] += 1

        # ì—ì´ì „íŠ¸ë³„ í†µê³„
        if agent_name not in self.metrics["requests_by_agent"]:
            self.metrics["requests_by_agent"][agent_name] = {
                "count": 0,
                "total_time": 0,
                "avg_response_length": 0
            }

        agent_stats = self.metrics["requests_by_agent"][agent_name]
        agent_stats["count"] += 1
        agent_stats["total_time"] += processing_time
        agent_stats["avg_response_length"] = (
            (agent_stats["avg_response_length"] * (agent_stats["count"] - 1) + response_length)
            / agent_stats["count"]
        )

        # ì „ì²´ í‰ê·  ì‘ë‹µ ê¸¸ì´ ê³„ì‚°
        self.metrics["average_response_length"] = (
            (self.metrics["average_response_length"] * (self.metrics["total_requests"] - 1) + response_length)
            / self.metrics["total_requests"]
        )

    def get_performance_report(self) -> str:
        """ì„±ëŠ¥ ë³´ê³ ì„œ ìƒì„±"""

        if self.metrics["total_requests"] == 0:
            return "ì„±ëŠ¥ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."

        avg_response_time = self.metrics["total_response_time"] / self.metrics["total_requests"]
        error_rate = (self.metrics["error_count"] / self.metrics["total_requests"]) * 100

        report = f"""
ğŸ“Š AgentScope ì„±ëŠ¥ ë³´ê³ ì„œ
{'='*40}

ğŸ“ˆ ì „ì²´ í†µê³„:
  - ì´ ìš”ì²­ ìˆ˜: {self.metrics['total_requests']}
  - í‰ê·  ì‘ë‹µ ì‹œê°„: {avg_response_time:.3f}ì´ˆ
  - ì˜¤ë¥˜ìœ¨: {error_rate:.1f}%
  - í‰ê·  ì‘ë‹µ ê¸¸ì´: {self.metrics['average_response_length']:.0f}ì

ğŸ¤– ì—ì´ì „íŠ¸ë³„ ì„±ëŠ¥:"""

        for agent_name, stats in self.metrics["requests_by_agent"].items():
            avg_time = stats["total_time"] / stats["count"] if stats["count"] > 0 else 0
            report += f"""
  {agent_name}:
    - ìš”ì²­ ìˆ˜: {stats['count']}
    - í‰ê·  ì‹œê°„: {avg_time:.3f}ì´ˆ
    - í‰ê·  ì‘ë‹µ ê¸¸ì´: {stats['avg_response_length']:.0f}ì"""

        return report

# ì‚¬ìš© ì˜ˆì œ
def comprehensive_debugging_demo():
    """ì¢…í•©ì ì¸ ë””ë²„ê¹… ë°ëª¨"""

    # ë””ë²„ê¹… ì—ì´ì „íŠ¸ ìƒì„±
    debug_agent = DebuggingAgent("debug_assistant")

    # ì„±ëŠ¥ ëª¨ë‹ˆí„° ìƒì„±
    monitor = PerformanceMonitor()

    # í…ŒìŠ¤íŠ¸ ë©”ì‹œì§€ë“¤
    test_messages = [
        "Hello, how are you?",
        "Explain quantum computing",
        "What's the weather like?",  # ì—ëŸ¬ ìœ ë°œ ê°€ëŠ¥
        "Tell me a joke"
    ]

    print("ğŸ” ì¢…í•© ë””ë²„ê¹… ë°ëª¨ ì‹œì‘")
    print("="*30)

    for i, message in enumerate(test_messages, 1):
        print(f"\nğŸ§ª í…ŒìŠ¤íŠ¸ #{i}: {message}")

        import time
        start_time = time.time()

        try:
            response = debug_agent.debug_run(message)
            processing_time = time.time() - start_time
            success = True

            print(f"âœ… ì„±ê³µ: {response.content[:50]}...")

        except Exception as e:
            processing_time = time.time() - start_time
            success = False

            print(f"âŒ ì‹¤íŒ¨: {str(e)}")

        # ì„±ëŠ¥ ì¶”ì 
        monitor.track_request(
            agent_name="debug_assistant",
            processing_time=processing_time,
            response_length=len(response.content) if success and response else 0,
            success=success
        )

    # ì„±ëŠ¥ ë³´ê³ ì„œ ì¶œë ¥
    print("\n" + monitor.get_performance_report())

# ì‹¤í–‰
if __name__ == "__main__":
    comprehensive_debugging_demo()
```

---

# 9. ì¶”ê°€ ë¦¬ì†ŒìŠ¤

## 9.1. ê³µì‹ ë¬¸ì„œ ë° í•™ìŠµ ìë£Œ
- **ê³µì‹ ë¬¸ì„œ**: https://doc.agentscope.io/
- **GitHub ì €ì¥ì†Œ**: https://github.com/agentscope-ai/agentscope
- **ë…¼ë¬¸**: "AgentScope: A Flexible yet Robust Multi-Agent Platform" (arXiv)
- **PyPI íŒ¨í‚¤ì§€**: https://pypi.org/project/agentscope/

## 9.2. ì»¤ë®¤ë‹ˆí‹° ë° ì§€ì›
- **GitHub Issues**: ë²„ê·¸ ë¦¬í¬íŠ¸ ë° ê¸°ëŠ¥ ìš”ì²­
- **GitHub Discussions**: ì»¤ë®¤ë‹ˆí‹° í† ë¡  ë° ì§ˆë¬¸
- **Medium ë¸”ë¡œê·¸**: AgentScope ê´€ë ¨ ê¸°ìˆ  ì•„í‹°í´

## 9.3. í™•ì¥ ë„êµ¬ ë° í†µí•©
- **AgentScope Studio**: ë“œë˜ê·¸ ì•¤ ë“œë¡­ ê°œë°œ í™˜ê²½
- **AgentScope Runtime**: í”„ë¡œë•ì…˜ ë°°í¬ìš© ëŸ°íƒ€ì„
- **ëª¨ë¸ ì§€ì›**: OpenAI, DashScope, Gemini, Anthropic, Ollama
- **ë°°í¬ ì˜µì…˜**: Docker, Kubernetes, í´ë¼ìš°ë“œ í”Œë«í¼

## 9.4. ê´€ë ¨ í”„ë ˆì„ì›Œí¬ ë¹„êµ
- **vs LangChain**: ë” ì§ê´€ì ì¸ ì—ì´ì „íŠ¸ ì¤‘ì‹¬ ì„¤ê³„
- **vs AutoGen**: ë“œë˜ê·¸ ì•¤ ë“œë¡­ UIì™€ ì•¡í„° ëª¨ë¸ ì§€ì›
- **vs CrewAI**: ë” ìœ ì—°í•œ ì•„í‚¤í…ì²˜ì™€ íˆ¬ëª…ì„±
- **vs Google ADK**: ì˜¤í”ˆì†ŒìŠ¤ì™€ ì»¤ë®¤ë‹ˆí‹° ì¤‘ì‹¬

---

# 10. ê²°ë¡ 

AgentScopeëŠ” **ì•Œë¦¬ë°”ë°”ì—ì„œ ê°œë°œí•œ í˜ì‹ ì ì¸ ë©€í‹° ì—ì´ì „íŠ¸ í”Œë«í¼**ìœ¼ë¡œ, ì—ì´ì „íŠ¸ ì§€í–¥ í”„ë¡œê·¸ë˜ë°ì˜ ìƒˆë¡œìš´ íŒ¨ëŸ¬ë‹¤ì„ì„ ì œì‹œí•©ë‹ˆë‹¤.

## âœ… AgentScopeë¥¼ ì„ íƒí•´ì•¼ í•˜ëŠ” ê²½ìš°
- **ë“œë˜ê·¸ ì•¤ ë“œë¡­ ê°œë°œ** ì„ í˜¸
- **ì™„ì „í•œ íˆ¬ëª…ì„±** í•„ìš” (ëª¨ë“  ë‚´ë¶€ ê³¼ì • ê°€ì‹œí™”)
- **ë³µì¡í•œ ë©€í‹° ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œ** êµ¬ì¶•
- **ë¹„ë™ê¸° ê³ ì„±ëŠ¥** ì²˜ë¦¬ í•„ìš”

## ğŸš€ 2025ë…„ í•µì‹¬ í˜ì‹ 
- **ì—ì´ì „íŠ¸ ì§€í–¥ í”„ë¡œê·¸ë˜ë°**: ìƒˆë¡œìš´ ê°œë°œ íŒ¨ëŸ¬ë‹¤ì„ ì œì‹œ
- **ë“œë˜ê·¸ ì•¤ ë“œë¡­ UI**: ì½”ë”© ì—†ëŠ” ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œ êµ¬ì„±
- **ì™„ì „í•œ ë¹„ë™ê¸° v1.0**: ê³ ì„±ëŠ¥ ë³‘ë ¬ ì²˜ë¦¬ ì§€ì›
- **AgentScope Studio**: í”„ë¡œë•ì…˜ ê¸‰ ê°œë°œ í™˜ê²½

## ğŸ’¼ ë…íŠ¹í•œ ê°€ì¹˜ ì œì•ˆ
- **ì œë¡œ ì½”ë“œ ê°œë°œ**: í”„ë¡œê·¸ë˜ë° ê²½í—˜ì´ ì ì–´ë„ êµ¬ì¶• ê°€ëŠ¥
- **ì•¡í„° ëª¨ë¸**: ìë™ ë³‘ë ¬ ìµœì í™”ì™€ ë¶„ì‚° ì²˜ë¦¬
- **ëª¨ë“ˆí˜• ë ˆê³  ì„¤ê³„**: ìœ ì—°í•œ ì¡°í•©ê³¼ í™•ì¥ì„±
- **ì•Œë¦¬ë°”ë°” ìƒíƒœê³„**: ëŒ€ê·œëª¨ ì„œë¹„ìŠ¤ ê²€ì¦ëœ ì•ˆì •ì„±

## ğŸ¯ íŠ¹ë³„í•œ ì í•©ì„±
- **ì—°êµ¬ê°œë°œíŒ€**: ë¹ ë¥¸ í”„ë¡œí† íƒ€ì´í•‘ê³¼ ì‹¤í—˜
- **ë¹„ê°œë°œì íŒ€**: ë“œë˜ê·¸ ì•¤ ë“œë¡­ìœ¼ë¡œ AI ì‹œìŠ¤í…œ êµ¬ì¶•
- **ëŒ€ê·œëª¨ ì‹œìŠ¤í…œ**: ì•¡í„° ëª¨ë¸ ê¸°ë°˜ í™•ì¥ì„±
- **êµìœ¡ ê¸°ê´€**: ì§ê´€ì ì¸ ë©€í‹° ì—ì´ì „íŠ¸ í•™ìŠµ ë„êµ¬

AgentScopeëŠ” **ì§ê´€ì ì´ë©´ì„œë„ ê°•ë ¥í•œ ë©€í‹° ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œ**ì„ êµ¬ì¶•í•˜ê³ ì í•˜ëŠ” ëª¨ë“  ê°œë°œìì™€ ì¡°ì§ì—ê²Œ ì™„ì „íˆ ìƒˆë¡œìš´ ê²½í—˜ì„ ì œê³µí•˜ëŠ” í˜ì‹ ì ì¸ í”Œë«í¼ì…ë‹ˆë‹¤.