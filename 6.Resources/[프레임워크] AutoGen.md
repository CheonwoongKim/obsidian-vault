---
title: "Microsoft AutoGen ì™„ì „ ê°€ì´ë“œ - ëŒ€í™”í˜• ë©€í‹° ì—ì´ì „íŠ¸"
type: resource
category: ê°œë°œë„êµ¬/AIí”„ë ˆì„ì›Œí¬
tags: [autogen, ë©€í‹°ì—ì´ì „íŠ¸, aií˜‘ì—…, ìë™í™”ë„êµ¬, íŒŒì´ì¬]
status: active
date: 2025-09-24
updated: 2025-09-24
source: ["AutoGen ê³µì‹ ë¬¸ì„œ", "Microsoft Research ë…¼ë¬¸", "ì‹¤ë¬´ í”„ë¡œì íŠ¸ ê²½í—˜"]
---

## ğŸ”— ê´€ë ¨ ê°€ì´ë“œ

### ë©€í‹° ì—ì´ì „íŠ¸ í”„ë ˆì„ì›Œí¬
- **[í”„ë ˆì„ì›Œí¬] Microsoft AutoGen ì™„ì „ ê°€ì´ë“œ - ëŒ€í™”í˜• ë©€í‹° ì—ì´ì „íŠ¸** â† **í˜„ì¬ ê°€ì´ë“œ**
- **[[í”„ë ˆì„ì›Œí¬] CrewAI]]** - ì—­í•  ê¸°ë°˜ ì‘ì—… ë¶„ë‹´ ì‹œìŠ¤í…œ
- **[[í”„ë ˆì„ì›Œí¬] Phidata]]** - ë‹¤ì–‘í•œ ëª¨ë‹¬ì„ í™œìš©í•˜ëŠ” ì—ì´ì „íŠ¸
- **[[í”„ë ˆì„ì›Œí¬] AgentScope]]** - ëŒ€ê·œëª¨ ë¦¬ìŠ¤ì¼€ì¼ ì—ì´ì „íŠ¸ í”Œë«í¼

### ê¸°ë³¸ AI í”„ë ˆì„ì›Œí¬
- **[[í”„ë ˆì„ì›Œí¬] LangChain]]** - ì¢…í•© AI ì• í”Œë¦¬ì¼€ì´ì…˜ í”„ë ˆì„ì›Œí¬
- **[[í”„ë ˆì„ì›Œí¬] LangGraph]]** - ë³µì¡í•œ ì›Œí¬í”Œë¡œìš° ì„¤ê³„
- **[[í”„ë ˆì„ì›Œí¬] DSPy]]** - í”„ë¡¬í”„íŠ¸ ìµœì í™”

### RAG ì‹œìŠ¤í…œ ê°€ì´ë“œ
- **[[í”„ë¡¬í”„íŠ¸] 11 Retrieval Augmented Generation (RAG) í”„ë¡¬í”„íŒ…]]** - RAG í”„ë¡¬í”„íŒ… ê¸°ë²•
- **[[[RAG] 04 ë¦¬íŠ¸ë¦¬ë²„(Retriever) ìµœì í™” ê°€ì´ë“œ]]** - ê²€ìƒ‰ ì‹œìŠ¤í…œ ì„±ëŠ¥ ê°œì„ 

### í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§
- **[[í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§ - ë§ˆìŠ¤í„° ê°€ì´ë“œ]]** - ì „ì²´ í”„ë¡¬í”„íŒ… ê¸°ë²• ê°œìš”
- **[[í”„ë¡¬í”„íŠ¸] 04 ReAct í”„ë¡¬í”„íŒ…]]** - ì¶”ë¡ ê³¼ ë„êµ¬ í™œìš© ê¸°ë²•

---

## 1. AutoGen ê°œìš”

**Microsoft AutoGen**ì€ ëŒ€í™”í˜• ë©€í‹° ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œ êµ¬ì¶•ì„ ìœ„í•œ í”„ë ˆì„ì›Œí¬ì…ë‹ˆë‹¤. ì—ì´ì „íŠ¸ ê°„ì˜ 'ëŒ€í™”'ë¥¼ í†µí•´ ë³µì¡í•œ ë¬¸ì œë¥¼ í˜‘ì—…ìœ¼ë¡œ í•´ê²°í•˜ëŠ” ê²ƒì´ í•µì‹¬ íŠ¹ì§•ì…ë‹ˆë‹¤.

### 1.1. í•µì‹¬ íŠ¹ì§•

- **ëŒ€í™” ì¤‘ì‹¬**: ì—ì´ì „íŠ¸ ê°„ ìì—°ìŠ¤ëŸ¬ìš´ ëŒ€í™”ë¡œ í˜‘ì—…
- **ì—­í•  íŠ¹í™”**: ê° ì—ì´ì „íŠ¸ê°€ ëª…í™•í•œ ì—­í• ê³¼ í˜ë¥´ì†Œë‚˜ ë³´ìœ 
- **ì½”ë“œ ì‹¤í–‰**: ì‹¤ì‹œê°„ ì½”ë“œ ìƒì„± ë° ì‹¤í–‰ í™˜ê²½ ì œê³µ
- **Human-in-the-Loop**: ì¸ê°„ì´ ëŒ€í™”ì— ìì—°ìŠ¤ëŸ½ê²Œ ì°¸ì—¬
- **í™•ì¥ì„±**: 2ëª…ë¶€í„° ìˆ˜ì‹­ëª…ê¹Œì§€ ì—ì´ì „íŠ¸ ìŠ¤ì¼€ì¼ë§

### 1.2. 2025ë…„ ì£¼ìš” ì—…ë°ì´íŠ¸

- **AutoGen Studio 2.0**: ë…¸ì½”ë“œ ì—ì´ì „íŠ¸ êµ¬ì„± í™˜ê²½
- **Multi-Modal ì§€ì›**: í…ìŠ¤íŠ¸, ì´ë¯¸ì§€, íŒŒì¼ ì²˜ë¦¬
- **Enterprise Features**: ëŒ€ê·œëª¨ ë°°í¬ ë° ê´€ë¦¬ ë„êµ¬
- **Advanced Workflows**: ë³µì¡í•œ ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§ ì§€ì›

---

## 2. ì„¤ì¹˜ ë° í™˜ê²½ ì„¤ì •

### 2.1. ê¸°ë³¸ ì„¤ì¹˜

```bash
# ê°€ìƒ í™˜ê²½ ìƒì„±
python -m venv autogen_env
source autogen_env/bin/activate  # macOS/Linux
# autogen_env\Scripts\activate  # Windows

# AutoGen ì„¤ì¹˜
pip install pyautogen

# ì„ íƒì  ì˜ì¡´ì„±
pip install pyautogen[teachable]  # í•™ìŠµ ê°€ëŠ¥ ì—ì´ì „íŠ¸
pip install pyautogen[lmm]        # ë©€í‹°ëª¨ë‹¬ ì§€ì›
pip install pyautogen[graph]      # ê·¸ë˜í”„ ì‹œê°í™”
pip install pyautogen[jupyter]    # Jupyter ë…¸íŠ¸ë¶ ì§€ì›
```

### 2.2. í™˜ê²½ ë³€ìˆ˜ ì„¤ì •

**.env íŒŒì¼:**
```env
# OpenAI
OPENAI_API_KEY=your_openai_api_key_here

# Azure OpenAI (ì„ íƒì‚¬í•­)
AZURE_OPENAI_API_KEY=your_azure_key
AZURE_OPENAI_ENDPOINT=https://your-resource.openai.azure.com/

# Other LLMs
ANTHROPIC_API_KEY=your_claude_key
GOOGLE_API_KEY=your_gemini_key
```

### 2.3. ì„¤ì • íŒŒì¼ (OAI_CONFIG_LIST.json)

```json
[
  {
    "model": "gpt-4",
    "api_key": "your_openai_api_key_here",
    "api_type": "openai"
  },
  {
    "model": "gpt-3.5-turbo",
    "api_key": "your_openai_api_key_here",
    "api_type": "openai"
  }
]
```

---

## 3. ê¸°ë³¸ ì‚¬ìš©ë²•

### 3.1. ì²« ë²ˆì§¸ ì—ì´ì „íŠ¸ ëŒ€í™”

```python
import autogen

# LLM ì„¤ì •
config_list = [
    {
        "model": "gpt-4",
        "api_key": "your_api_key_here"
    }
]

llm_config = {
    "config_list": config_list,
    "temperature": 0.7,
    "timeout": 120,
}

# ì‚¬ìš©ì í”„ë¡ì‹œ (ì¸ê°„ ëŒ€í‘œ)
user_proxy = autogen.UserProxyAgent(
    name="user_proxy",
    human_input_mode="NEVER",  # ìë™ ì‹¤í–‰
    max_consecutive_auto_reply=10,
    is_termination_msg=lambda x: x.get("content", "").rstrip().endswith("TERMINATE"),
    code_execution_config={
        "work_dir": "coding",
        "use_docker": False,  # Docker ì‚¬ìš© ì‹œ True
    },
)

# AI ì–´ì‹œìŠ¤í„´íŠ¸
assistant = autogen.AssistantAgent(
    name="assistant",
    llm_config=llm_config,
)

# ëŒ€í™” ì‹œì‘
user_proxy.initiate_chat(
    assistant,
    message="íŒŒì´ì¬ìœ¼ë¡œ í”¼ë³´ë‚˜ì¹˜ ìˆ˜ì—´ì„ ìƒì„±í•˜ëŠ” í•¨ìˆ˜ë¥¼ ì‘ì„±í•˜ê³  í…ŒìŠ¤íŠ¸í•´ì£¼ì„¸ìš”."
)
```

### 3.2. ë‹¤ì¤‘ ì—ì´ì „íŠ¸ í˜‘ì—…

```python
# ì „ë¬¸ê°€ ì—ì´ì „íŠ¸ë“¤
data_scientist = autogen.AssistantAgent(
    name="data_scientist",
    llm_config=llm_config,
    system_message="""
    ë‹¹ì‹ ì€ ë°ì´í„° ì‚¬ì´ì–¸í‹°ìŠ¤íŠ¸ì…ë‹ˆë‹¤.
    - ë°ì´í„° ë¶„ì„ê³¼ ë¨¸ì‹ ëŸ¬ë‹ì— ì „ë¬¸ì„±ì„ ê°€ì§€ê³  ìˆìŠµë‹ˆë‹¤.
    - í†µê³„ì  ì ‘ê·¼ê³¼ ì‹œê°í™”ë¥¼ ì¤‘ìš”ì‹œí•©ë‹ˆë‹¤.
    - ì½”ë“œëŠ” pandas, numpy, matplotlibì„ ì£¼ë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤.
    """
)

software_engineer = autogen.AssistantAgent(
    name="software_engineer",
    llm_config=llm_config,
    system_message="""
    ë‹¹ì‹ ì€ ì†Œí”„íŠ¸ì›¨ì–´ ì—”ì§€ë‹ˆì–´ì…ë‹ˆë‹¤.
    - ê¹”ë”í•˜ê³  ìœ ì§€ë³´ìˆ˜ ê°€ëŠ¥í•œ ì½”ë“œ ì‘ì„±ì„ ì¤‘ìš”ì‹œí•©ë‹ˆë‹¤.
    - ì„±ëŠ¥ ìµœì í™”ì™€ ì—ëŸ¬ ì²˜ë¦¬ì— ì‹ ê²½ì”ë‹ˆë‹¤.
    - í…ŒìŠ¤íŠ¸ ì½”ë“œ ì‘ì„±ì„ í•„ìˆ˜ë¡œ í•©ë‹ˆë‹¤.
    """
)

# ê·¸ë£¹ ì±„íŒ… ì„¤ì •
groupchat = autogen.GroupChat(
    agents=[user_proxy, data_scientist, software_engineer],
    messages=[],
    max_round=20,
    speaker_selection_method="round_robin"  # ë˜ëŠ” "auto"
)

manager = autogen.GroupChatManager(
    groupchat=groupchat,
    llm_config=llm_config
)

# í˜‘ì—… ì‹œì‘
user_proxy.initiate_chat(
    manager,
    message="""
    ê³ ê° ë°ì´í„° ë¶„ì„ ì‹œìŠ¤í…œì„ ë§Œë“¤ì–´ì£¼ì„¸ìš”.
    - CSV íŒŒì¼ì„ ì½ì–´ì„œ ê¸°ë³¸ í†µê³„ë¥¼ ë¶„ì„í•˜ê³ 
    - ì‹œê°í™” ì°¨íŠ¸ë¥¼ ìƒì„±í•˜ë©°
    - ê²°ê³¼ë¥¼ ì›¹ ëŒ€ì‹œë³´ë“œë¡œ í‘œì‹œí•˜ëŠ” ì‹œìŠ¤í…œì´ í•„ìš”í•©ë‹ˆë‹¤.
    """
)
```

---

## 4. ê³ ê¸‰ ê¸°ëŠ¥

### 4.1. ì½”ë“œ ì‹¤í–‰ í™˜ê²½

```python
# Docker ê¸°ë°˜ ì½”ë“œ ì‹¤í–‰
user_proxy = autogen.UserProxyAgent(
    name="user_proxy",
    human_input_mode="TERMINATE",
    code_execution_config={
        "work_dir": "workspace",
        "use_docker": True,
        "timeout": 60,
        "last_n_messages": 3,
    }
)

# ì»¤ìŠ¤í…€ ì‹¤í–‰ í•¨ìˆ˜
def custom_execution_function(code: str, lang: str) -> tuple:
    """ì»¤ìŠ¤í…€ ì½”ë“œ ì‹¤í–‰ ë¡œì§"""
    if lang == "python":
        # ë³´ì•ˆ ê²€ì‚¬
        forbidden = ["import os", "import subprocess", "exec("]
        if any(f in code for f in forbidden):
            return 1, "ë³´ì•ˆìƒ í—ˆìš©ë˜ì§€ ì•ŠëŠ” ì½”ë“œì…ë‹ˆë‹¤."

        # ì‹¤í–‰
        try:
            exec_globals = {"__builtins__": __builtins__}
            exec(code, exec_globals)
            return 0, "ì½”ë“œê°€ ì„±ê³µì ìœ¼ë¡œ ì‹¤í–‰ë˜ì—ˆìŠµë‹ˆë‹¤."
        except Exception as e:
            return 1, f"ì‹¤í–‰ ì˜¤ë¥˜: {str(e)}"

    return 1, "ì§€ì›ë˜ì§€ ì•ŠëŠ” ì–¸ì–´ì…ë‹ˆë‹¤."

# ì»¤ìŠ¤í…€ ì‹¤í–‰ê¸° ì ìš©
user_proxy.code_execution_config["function"] = custom_execution_function
```

### 4.2. ì „ë¬¸ê°€ ì—ì´ì „íŠ¸ í˜ë¥´ì†Œë‚˜

```python
# ì½”ë“œ ë¦¬ë·°ì–´
code_reviewer = autogen.AssistantAgent(
    name="code_reviewer",
    llm_config=llm_config,
    system_message="""
    ë‹¹ì‹ ì€ ì‹œë‹ˆì–´ ì½”ë“œ ë¦¬ë·°ì–´ì…ë‹ˆë‹¤.

    ê²€í†  ê¸°ì¤€:
    1. ì½”ë“œ í’ˆì§ˆ: ê°€ë…ì„±, ìœ ì§€ë³´ìˆ˜ì„±, ì¼ê´€ì„±
    2. ì„±ëŠ¥: ì‹œê°„/ê³µê°„ ë³µì¡ë„, ë³‘ëª© ì§€ì 
    3. ë³´ì•ˆ: ì·¨ì•½ì , ì…ë ¥ ê²€ì¦, ê¶Œí•œ ê´€ë¦¬
    4. í…ŒìŠ¤íŠ¸: ì»¤ë²„ë¦¬ì§€, ì—£ì§€ ì¼€ì´ìŠ¤

    ì¶œë ¥ í˜•ì‹:
    - ìš”ì•½: ì „ë°˜ì ì¸ í‰ê°€
    - ì£¼ìš” ì´ìŠˆ: ì‹¬ê°ë„ë³„ ë¶„ë¥˜
    - ê°œì„  ì œì•ˆ: êµ¬ì²´ì ì¸ ì½”ë“œ ì˜ˆì‹œ í¬í•¨
    - ìŠ¹ì¸ ì—¬ë¶€: APPROVED/NEEDS_REVISION
    """
)

# QA í…ŒìŠ¤í„°
qa_tester = autogen.AssistantAgent(
    name="qa_tester",
    llm_config=llm_config,
    system_message="""
    ë‹¹ì‹ ì€ QA í…ŒìŠ¤í„°ì…ë‹ˆë‹¤.

    í…ŒìŠ¤íŠ¸ ì „ëµ:
    1. ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸: ìš”êµ¬ì‚¬í•­ ì¶©ì¡± ì—¬ë¶€
    2. ê²½ê³„ê°’ í…ŒìŠ¤íŠ¸: ê·¹ë‹¨ì  ì…ë ¥ê°’
    3. ì˜¤ë¥˜ ì²˜ë¦¬: ì˜ˆì™¸ ìƒí™© ëŒ€ì‘
    4. ì‚¬ìš©ì„±: ì§ê´€ì  ì¸í„°í˜ì´ìŠ¤

    í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ëŠ” Given-When-Then í˜•ì‹ìœ¼ë¡œ ì‘ì„±í•©ë‹ˆë‹¤.
    """
)

# í”„ë¡œë•íŠ¸ ë§¤ë‹ˆì €
product_manager = autogen.AssistantAgent(
    name="product_manager",
    llm_config=llm_config,
    system_message="""
    ë‹¹ì‹ ì€ í”„ë¡œë•íŠ¸ ë§¤ë‹ˆì €ì…ë‹ˆë‹¤.

    ì±…ì„ ì˜ì—­:
    1. ìš”êµ¬ì‚¬í•­ ëª…í™•í™”: ëª¨í˜¸í•œ ìš”êµ¬ì‚¬í•­ì„ êµ¬ì²´í™”
    2. ìš°ì„ ìˆœìœ„ ê²°ì •: ê¸°ëŠ¥ë³„ ì¤‘ìš”ë„ì™€ ê¸´ê¸‰ë„
    3. ì‚¬ìš©ì ê´€ì : ì‹¤ì œ ì‚¬ìš© ì‹œë‚˜ë¦¬ì˜¤ ê³ ë ¤
    4. ë¹„ì¦ˆë‹ˆìŠ¤ ì„íŒ©íŠ¸: ROIì™€ KPI ì˜í–¥ ë¶„ì„

    ì˜ì‚¬ê²°ì •ì€ ë°ì´í„°ì™€ ì‚¬ìš©ì í”¼ë“œë°±ì— ê¸°ë°˜í•©ë‹ˆë‹¤.
    """
)
```

### 4.3. ì¡°ê±´ë¶€ ì›Œí¬í”Œë¡œìš°

```python
# ì¡°ê±´ë¶€ ì—ì´ì „íŠ¸ ì„ íƒ
def custom_speaker_selection_func(last_speaker, groupchat):
    """ë§ˆì§€ë§‰ ë©”ì‹œì§€ ë‚´ìš©ì— ë”°ë¼ ë‹¤ìŒ ë°œì–¸ì ê²°ì •"""
    messages = groupchat.messages
    if not messages:
        return None

    last_message = messages[-1]["content"]

    # í‚¤ì›Œë“œ ê¸°ë°˜ ë¼ìš°íŒ…
    if "ì½”ë“œ" in last_message or "í•¨ìˆ˜" in last_message:
        return software_engineer
    elif "ë°ì´í„°" in last_message or "ë¶„ì„" in last_message:
        return data_scientist
    elif "í…ŒìŠ¤íŠ¸" in last_message or "ë²„ê·¸" in last_message:
        return qa_tester
    elif "ìš”êµ¬ì‚¬í•­" in last_message or "ê¸°ëŠ¥" in last_message:
        return product_manager

    return None  # ìë™ ì„ íƒ

# ê·¸ë£¹ ì±„íŒ…ì— ì ìš©
groupchat = autogen.GroupChat(
    agents=[user_proxy, software_engineer, data_scientist, qa_tester, product_manager],
    messages=[],
    max_round=30,
    speaker_selection_method=custom_speaker_selection_func
)
```

---

## 5. ì‹¤ë¬´ íŒ¨í„´

### 5.1. ì½”ë“œ ê°œë°œ íŒŒì´í”„ë¼ì¸

```python
class CodeDevelopmentPipeline:
    def __init__(self, config_list):
        self.llm_config = {"config_list": config_list, "temperature": 0.3}
        self.setup_agents()

    def setup_agents(self):
        # ìš”êµ¬ì‚¬í•­ ë¶„ì„ê°€
        self.analyst = autogen.AssistantAgent(
            name="analyst",
            llm_config=self.llm_config,
            system_message="ìš”êµ¬ì‚¬í•­ì„ ë¶„ì„í•˜ê³  ê¸°ìˆ  ìŠ¤í™ì„ ì‘ì„±í•˜ëŠ” ì „ë¬¸ê°€"
        )

        # ê°œë°œì
        self.developer = autogen.AssistantAgent(
            name="developer",
            llm_config=self.llm_config,
            system_message="í´ë¦° ì½”ë“œì™€ Best Practiceë¥¼ ë”°ë¥´ëŠ” ê°œë°œì"
        )

        # ë¦¬ë·°ì–´
        self.reviewer = autogen.AssistantAgent(
            name="reviewer",
            llm_config=self.llm_config,
            system_message="ì½”ë“œ í’ˆì§ˆê³¼ ë³´ì•ˆì„ ê²€í† í•˜ëŠ” ì‹œë‹ˆì–´ ê°œë°œì"
        )

        # í…ŒìŠ¤í„°
        self.tester = autogen.AssistantAgent(
            name="tester",
            llm_config=self.llm_config,
            system_message="í¬ê´„ì ì¸ í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ë¥¼ ì‘ì„±í•˜ëŠ” QA ì—”ì§€ë‹ˆì–´"
        )

        # ì‚¬ìš©ì í”„ë¡ì‹œ
        self.user_proxy = autogen.UserProxyAgent(
            name="user_proxy",
            human_input_mode="NEVER",
            code_execution_config={"work_dir": "development", "use_docker": True}
        )

    def develop_feature(self, requirements):
        """ê¸°ëŠ¥ ê°œë°œ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰"""
        agents = [self.user_proxy, self.analyst, self.developer, self.reviewer, self.tester]

        groupchat = autogen.GroupChat(
            agents=agents,
            messages=[],
            max_round=50,
            speaker_selection_method="round_robin"
        )

        manager = autogen.GroupChatManager(groupchat=groupchat, llm_config=self.llm_config)

        # ê°œë°œ í”„ë¡œì„¸ìŠ¤ ì‹œì‘
        self.user_proxy.initiate_chat(
            manager,
            message=f"""
            ë‹¤ìŒ ìš”êµ¬ì‚¬í•­ì— ë”°ë¼ ê¸°ëŠ¥ì„ ê°œë°œí•´ì£¼ì„¸ìš”:

            {requirements}

            í”„ë¡œì„¸ìŠ¤:
            1. Analyst: ìš”êµ¬ì‚¬í•­ ë¶„ì„ ë° ê¸°ìˆ  ìŠ¤í™ ì‘ì„±
            2. Developer: ì½”ë“œ êµ¬í˜„
            3. Reviewer: ì½”ë“œ ë¦¬ë·° ë° ê°œì„  ì œì•ˆ
            4. Tester: í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ ì‘ì„± ë° ì‹¤í–‰
            5. í•„ìš”ì‹œ ë°˜ë³µ ê°œì„ 

            ìµœì¢…ì ìœ¼ë¡œ í”„ë¡œë•ì…˜ ë ˆë”” ì½”ë“œë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.
            """
        )

# ì‚¬ìš© ì˜ˆì‹œ
pipeline = CodeDevelopmentPipeline(config_list)
pipeline.develop_feature("""
ì‚¬ìš©ì ì¸ì¦ ì‹œìŠ¤í…œì„ êµ¬í˜„í•´ì£¼ì„¸ìš”.
- ì´ë©”ì¼/íŒ¨ìŠ¤ì›Œë“œ ë¡œê·¸ì¸
- JWT í† í° ê¸°ë°˜ ì¸ì¦
- ë¹„ë°€ë²ˆí˜¸ í•´ì‹± (bcrypt)
- ë¡œê·¸ì¸ ì‹œë„ ì œí•œ
- íŒ¨ìŠ¤ì›Œë“œ ì¬ì„¤ì • ê¸°ëŠ¥
""")
```

### 5.2. ì—°êµ¬ ë° ë¶„ì„ íŒ€

```python
class ResearchTeam:
    def __init__(self, config_list):
        self.llm_config = {"config_list": config_list, "temperature": 0.7}
        self.setup_research_agents()

    def setup_research_agents(self):
        # ë¦¬ì„œì²˜
        self.researcher = autogen.AssistantAgent(
            name="researcher",
            llm_config=self.llm_config,
            system_message="""
            ë‹¹ì‹ ì€ ì—°êµ¬ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
            - ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ì¶œì²˜ì—ì„œ ì •ë³´ë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤
            - ë‹¤ê°ë„ì—ì„œ ì£¼ì œë¥¼ ë¶„ì„í•©ë‹ˆë‹¤
            - í¸í–¥ì„ í”¼í•˜ê³  ê°ê´€ì ì¸ ì‹œê°ì„ ìœ ì§€í•©ë‹ˆë‹¤
            - ì¶œì²˜ë¥¼ ëª…í™•íˆ ì¸ìš©í•©ë‹ˆë‹¤
            """
        )

        # ë¶„ì„ê°€
        self.analyst = autogen.AssistantAgent(
            name="analyst",
            llm_config=self.llm_config,
            system_message="""
            ë‹¹ì‹ ì€ ë°ì´í„° ë¶„ì„ê°€ì…ë‹ˆë‹¤.
            - ìˆ˜ì§‘ëœ ì •ë³´ë¥¼ ì²´ê³„ì ìœ¼ë¡œ ë¶„ì„í•©ë‹ˆë‹¤
            - íŒ¨í„´ê³¼ íŠ¸ë Œë“œë¥¼ ì‹ë³„í•©ë‹ˆë‹¤
            - ì •ëŸ‰ì /ì •ì„±ì  ë¶„ì„ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤
            - ê²°ë¡ ì„ ë’·ë°›ì¹¨í•˜ëŠ” ì¦ê±°ë¥¼ ì œì‹œí•©ë‹ˆë‹¤
            """
        )

        # ì‘ì„±ì
        self.writer = autogen.AssistantAgent(
            name="writer",
            llm_config=self.llm_config,
            system_message="""
            ë‹¹ì‹ ì€ ê¸°ìˆ  ì‘ì„±ìì…ë‹ˆë‹¤.
            - ë³µì¡í•œ ë‚´ìš©ì„ ëª…í™•í•˜ê²Œ ì „ë‹¬í•©ë‹ˆë‹¤
            - ëŒ€ìƒ ë…ìì— ë§ì¶° í†¤ì„ ì¡°ì ˆí•©ë‹ˆë‹¤
            - êµ¬ì¡°ì ì´ê³  ë…¼ë¦¬ì ì¸ ê¸€ì„ ì‘ì„±í•©ë‹ˆë‹¤
            - ì‹œê°ì  ìš”ì†Œ(ì°¨íŠ¸, ë‹¤ì´ì–´ê·¸ë¨)ë¥¼ í™œìš©í•©ë‹ˆë‹¤
            """
        )

        self.user_proxy = autogen.UserProxyAgent(
            name="user_proxy",
            human_input_mode="NEVER",
            code_execution_config={"work_dir": "research"}
        )

    def conduct_research(self, topic, output_format="report"):
        """ì—°êµ¬ ìˆ˜í–‰ ë° ë³´ê³ ì„œ ìƒì„±"""
        agents = [self.user_proxy, self.researcher, self.analyst, self.writer]

        groupchat = autogen.GroupChat(
            agents=agents,
            messages=[],
            max_round=30,
            speaker_selection_method="auto"
        )

        manager = autogen.GroupChatManager(groupchat=groupchat, llm_config=self.llm_config)

        message = f"""
        ë‹¤ìŒ ì£¼ì œì— ëŒ€í•œ ì¢…í•©ì ì¸ ì—°êµ¬ë¥¼ ìˆ˜í–‰í•´ì£¼ì„¸ìš”: {topic}

        ì—°êµ¬ í”„ë¡œì„¸ìŠ¤:
        1. Researcher: ê´€ë ¨ ì •ë³´ ìˆ˜ì§‘ ë° ì¶œì²˜ ì •ë¦¬
        2. Analyst: ìˆ˜ì§‘ëœ ë°ì´í„° ë¶„ì„ ë° ì¸ì‚¬ì´íŠ¸ ë„ì¶œ
        3. Writer: {output_format} í˜•íƒœë¡œ ìµœì¢… ë¬¸ì„œ ì‘ì„±

        ìµœì¢… ê²°ê³¼ë¬¼ì€ ë‹¤ìŒì„ í¬í•¨í•´ì•¼ í•©ë‹ˆë‹¤:
        - ì£¼ìš” ë°œê²¬ì‚¬í•­
        - íŠ¸ë Œë“œ ë° íŒ¨í„´
        - ì‹¤ë¬´ ì ìš© ë°©ì•ˆ
        - í–¥í›„ ì „ë§
        - ì°¸ê³  ë¬¸í—Œ
        """

        self.user_proxy.initiate_chat(manager, message=message)

# ì‚¬ìš© ì˜ˆì‹œ
research_team = ResearchTeam(config_list)
research_team.conduct_research(
    "2025ë…„ ìƒì„±í˜• AIì˜ ê¸°ì—… ë„ì… í˜„í™©ê³¼ ì „ë§",
    output_format="executive_summary"
)
```

---

## 6. AutoGen Studio ì‚¬ìš©ë²•

### 6.1. ì„¤ì¹˜ ë° ì‹¤í–‰

```bash
# AutoGen Studio ì„¤ì¹˜
pip install autogenstudio

# ì‹¤í–‰
autogenstudio ui --port 8081
```

### 6.2. ì›¹ ì¸í„°í˜ì´ìŠ¤ í™œìš©

**ì£¼ìš” ê¸°ëŠ¥:**
- **ë“œë˜ê·¸ ì•¤ ë“œë¡­**: ì—ì´ì „íŠ¸ ì‹œê°ì  êµ¬ì„±
- **í…œí”Œë¦¿**: ì‚¬ì „ ì •ì˜ëœ ì—ì´ì „íŠ¸ ì—­í• 
- **ì‹¤ì‹œê°„ ì±„íŒ…**: ì›¹ UIì—ì„œ ì§ì ‘ ëŒ€í™”
- **ì›Œí¬í”Œë¡œìš° ì €ì¥**: ì¬ì‚¬ìš© ê°€ëŠ¥í•œ ì„¤ì • ì €ì¥

**ì—ì´ì „íŠ¸ êµ¬ì„±:**
```json
{
  "name": "research_assistant",
  "type": "assistant",
  "system_message": "ì—°êµ¬ ë³´ì¡° ì „ë¬¸ê°€",
  "llm_config": {
    "model": "gpt-4",
    "temperature": 0.7
  },
  "tools": ["web_search", "file_reader"]
}
```

---

## 7. ì„±ëŠ¥ ìµœì í™”

### 7.1. í† í° ì‚¬ìš©ëŸ‰ ìµœì í™”

```python
# ëŒ€í™” íˆìŠ¤í† ë¦¬ ê´€ë¦¬
def trim_conversation_history(messages, max_tokens=4000):
    """í† í° ìˆ˜ë¥¼ ì œí•œí•˜ì—¬ ë¹„ìš© ì ˆì•½"""
    total_tokens = sum(len(msg["content"].split()) for msg in messages)

    if total_tokens <= max_tokens:
        return messages

    # ì¤‘ìš”í•œ ë©”ì‹œì§€ ë³´ì¡´ (ì‹œìŠ¤í…œ ë©”ì‹œì§€, ìµœê·¼ ë©”ì‹œì§€)
    system_messages = [msg for msg in messages if msg.get("role") == "system"]
    recent_messages = messages[-10:]  # ìµœê·¼ 10ê°œ ë©”ì‹œì§€

    return system_messages + recent_messages

# ì—ì´ì „íŠ¸ì— ì ìš©
user_proxy = autogen.UserProxyAgent(
    name="user_proxy",
    max_consecutive_auto_reply=5,  # ìë™ ì‘ë‹µ ì œí•œ
    # ì»¤ìŠ¤í…€ ë©”ì‹œì§€ ì²˜ë¦¬
)
```

### 7.2. ë³‘ë ¬ ì²˜ë¦¬

```python
import asyncio
from concurrent.futures import ThreadPoolExecutor

class ParallelAutoGen:
    def __init__(self, config_list):
        self.config_list = config_list
        self.executor = ThreadPoolExecutor(max_workers=4)

    async def run_multiple_conversations(self, tasks):
        """ì—¬ëŸ¬ ëŒ€í™”ë¥¼ ë³‘ë ¬ë¡œ ì‹¤í–‰"""
        loop = asyncio.get_event_loop()

        futures = []
        for task in tasks:
            future = loop.run_in_executor(
                self.executor,
                self.run_single_conversation,
                task
            )
            futures.append(future)

        results = await asyncio.gather(*futures)
        return results

    def run_single_conversation(self, task):
        """ë‹¨ì¼ ëŒ€í™” ì‹¤í–‰"""
        # AutoGen ì—ì´ì „íŠ¸ ì„¤ì • ë° ì‹¤í–‰
        user_proxy = autogen.UserProxyAgent(
            name="user_proxy",
            human_input_mode="NEVER",
        )

        assistant = autogen.AssistantAgent(
            name="assistant",
            llm_config={"config_list": self.config_list}
        )

        user_proxy.initiate_chat(assistant, message=task["message"])
        return user_proxy.chat_messages

# ì‚¬ìš© ì˜ˆì‹œ
parallel_system = ParallelAutoGen(config_list)

tasks = [
    {"message": "íŒŒì´ì¬ ë¦¬ìŠ¤íŠ¸ ì •ë ¬ ì•Œê³ ë¦¬ì¦˜ ì„¤ëª…í•´ì¤˜"},
    {"message": "ë°ì´í„°ë² ì´ìŠ¤ ì¸ë±ìŠ¤ ìµœì í™” ë°©ë²•ì€?"},
    {"message": "RESTful API ì„¤ê³„ ì›ì¹™ì„ ì•Œë ¤ì¤˜"}
]

results = asyncio.run(parallel_system.run_multiple_conversations(tasks))
```

---

## 8. íŠ¸ëŸ¬ë¸”ìŠˆíŒ…

### 8.1. ì¼ë°˜ì ì¸ ë¬¸ì œë“¤

**1. ì—ì´ì „íŠ¸ê°€ ë¬´í•œ ëŒ€í™”ì— ë¹ ì§€ëŠ” ê²½ìš°**
```python
# í•´ê²°ì±…: ëª…í™•í•œ ì¢…ë£Œ ì¡°ê±´ ì„¤ì •
user_proxy = autogen.UserProxyAgent(
    name="user_proxy",
    max_consecutive_auto_reply=10,
    is_termination_msg=lambda x: "TERMINATE" in x.get("content", "").upper(),
)

# ì¢…ë£Œ ë©”ì‹œì§€ë¥¼ ëª…ì‹œì ìœ¼ë¡œ ìš”ì²­
system_message = """
ì‘ì—…ì„ ì™„ë£Œí•˜ë©´ ë°˜ë“œì‹œ 'TERMINATE'ë¡œ ì‘ë‹µì„ ë§ˆë¬´ë¦¬í•˜ì„¸ìš”.
"""
```

**2. ì½”ë“œ ì‹¤í–‰ ì˜¤ë¥˜**
```python
# Docker í™˜ê²½ ë¬¸ì œ í•´ê²°
code_execution_config = {
    "work_dir": "workspace",
    "use_docker": False,  # Docker ë¬¸ì œ ì‹œ Falseë¡œ ì„¤ì •
    "timeout": 60,
    "last_n_messages": 3,
}

# ê¶Œí•œ ë¬¸ì œ í•´ê²°
import os
os.makedirs("workspace", exist_ok=True)
os.chmod("workspace", 0o755)
```

**3. API ìš”ì²­ í•œë„ ì´ˆê³¼**
```python
# ìš”ì²­ ê°„ê²© ì¡°ì ˆ
import time

def rate_limited_config():
    return {
        "config_list": config_list,
        "timeout": 120,
        "retry_wait_time": 30,  # ì¬ì‹œë„ ëŒ€ê¸° ì‹œê°„
        "max_retries": 3,
    }
```

### 8.2. ë””ë²„ê¹… ë„êµ¬

```python
# ëŒ€í™” ë¡œê·¸ ì €ì¥
import json
import logging

logging.basicConfig(level=logging.INFO)

def save_conversation_log(chat_messages, filename):
    """ëŒ€í™” ë‚´ìš©ì„ íŒŒì¼ë¡œ ì €ì¥"""
    with open(f"logs/{filename}.json", "w", encoding="utf-8") as f:
        json.dump(chat_messages, f, ensure_ascii=False, indent=2)

# ë©”ì‹œì§€ ë¶„ì„
def analyze_conversation(messages):
    """ëŒ€í™” íŒ¨í„´ ë¶„ì„"""
    stats = {
        "total_messages": len(messages),
        "agents": set(),
        "average_length": 0,
        "termination_found": False
    }

    total_length = 0
    for msg in messages:
        if "name" in msg:
            stats["agents"].add(msg["name"])

        content = msg.get("content", "")
        total_length += len(content)

        if "TERMINATE" in content.upper():
            stats["termination_found"] = True

    stats["average_length"] = total_length / len(messages) if messages else 0
    stats["agents"] = list(stats["agents"])

    return stats

# ì‚¬ìš©
conversation_stats = analyze_conversation(user_proxy.chat_messages)
print(json.dumps(conversation_stats, indent=2))
```

---

## 9. ë² ìŠ¤íŠ¸ í”„ë™í‹°ìŠ¤

### 9.1. ì—ì´ì „íŠ¸ ì„¤ê³„ ì›ì¹™

```python
# 1. ëª…í™•í•œ ì—­í•  ì •ì˜
good_system_message = """
ë‹¹ì‹ ì€ Python ë°±ì—”ë“œ ê°œë°œìì…ë‹ˆë‹¤.

ì „ë¬¸ ì˜ì—­:
- FastAPI, Django í”„ë ˆì„ì›Œí¬
- PostgreSQL, Redis ë°ì´í„°ë² ì´ìŠ¤
- Docker, Kubernetes ë°°í¬

ì‘ì—… ë°©ì‹:
- ì½”ë“œëŠ” PEP8 ìŠ¤íƒ€ì¼ì„ ë”°ë¦…ë‹ˆë‹¤
- ì—ëŸ¬ ì²˜ë¦¬ë¥¼ ë°˜ë“œì‹œ í¬í•¨í•©ë‹ˆë‹¤
- ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ë¥¼ í•¨ê»˜ ì œê³µí•©ë‹ˆë‹¤
- ë³´ì•ˆ ì·¨ì•½ì ì„ ì ê²€í•©ë‹ˆë‹¤

ê²°ê³¼ í˜•ì‹:
- ì½”ë“œ ë¸”ë¡ + ì„¤ëª…
- ì‹¤í–‰ ë°©ë²• ì•ˆë‚´
- ì£¼ì˜ì‚¬í•­ ëª…ì‹œ
"""

# 2. ìƒí˜¸ì‘ìš© í”„ë¡œí† ì½œ
interaction_protocol = """
ë‹¤ë¥¸ ì—ì´ì „íŠ¸ì™€ í˜‘ì—… ì‹œ:
- @ì—ì´ì „íŠ¸ëª…ìœ¼ë¡œ ì§ì ‘ ì–¸ê¸‰
- ì™„ë£Œëœ ì‘ì—…ì€ "âœ… ì™„ë£Œ: [ì‘ì—…ë‚´ìš©]" í˜•ì‹
- ë„ì›€ ìš”ì²­ì€ "ğŸ†˜ ìš”ì²­: [êµ¬ì²´ì  ë‚´ìš©]" í˜•ì‹
- ì˜ê²¬ ì¶©ëŒ ì‹œ ê·¼ê±°ì™€ ëŒ€ì•ˆ ì œì‹œ
"""
```

### 9.2. ì›Œí¬í”Œë¡œìš° ìµœì í™”

```python
class OptimizedWorkflow:
    def __init__(self):
        self.conversation_history = []
        self.performance_metrics = {}

    def create_focused_agent(self, role, expertise_areas, prohibited_areas=None):
        """ì§‘ì¤‘ëœ ì „ë¬¸ì„±ì„ ê°€ì§„ ì—ì´ì „íŠ¸ ìƒì„±"""
        prohibited = prohibited_areas or []

        system_message = f"""
        ì—­í• : {role}
        ì „ë¬¸ ë¶„ì•¼: {', '.join(expertise_areas)}

        ì‘ì—… ë²”ìœ„:
        - ì „ë¬¸ ë¶„ì•¼ ë‚´ ì§ˆë¬¸ì—ë§Œ ë‹µë³€í•©ë‹ˆë‹¤
        - ë²”ìœ„ ë°– ì§ˆë¬¸ì€ ì ì ˆí•œ ì „ë¬¸ê°€ì—ê²Œ ë¼ìš°íŒ…í•©ë‹ˆë‹¤

        ê¸ˆì§€ ì˜ì—­: {', '.join(prohibited)}
        ì´ ì˜ì—­ì˜ ì§ˆë¬¸ì„ ë°›ìœ¼ë©´ "ì´ ì§ˆë¬¸ì€ {ì „ë¬¸ê°€}ì—ê²Œ ì „ë‹¬í•˜ê² ìŠµë‹ˆë‹¤"ë¼ê³  ì‘ë‹µí•˜ì„¸ìš”.
        """

        return autogen.AssistantAgent(
            name=role.lower().replace(" ", "_"),
            llm_config=self.llm_config,
            system_message=system_message
        )

    def measure_performance(self, start_time, end_time, message_count, tokens_used):
        """ì„±ëŠ¥ ì§€í‘œ ì¸¡ì •"""
        duration = end_time - start_time
        self.performance_metrics.update({
            "duration_seconds": duration,
            "messages_per_second": message_count / duration,
            "tokens_per_message": tokens_used / message_count if message_count > 0 else 0,
            "efficiency_score": (message_count * 100) / tokens_used if tokens_used > 0 else 0
        })
        return self.performance_metrics
```

---

## 10. ì‹¤ìŠµ í”„ë¡œì íŠ¸

### 10.1. ì†Œí”„íŠ¸ì›¨ì–´ ê°œë°œíŒ€ ì‹œë®¬ë ˆì´ì…˜

```python
class SoftwareDevelopmentTeam:
    def __init__(self, config_list):
        self.config_list = config_list
        self.setup_team()

    def setup_team(self):
        """ê°œë°œíŒ€ êµ¬ì„±"""
        base_config = {"config_list": self.config_list, "temperature": 0.5}

        # íŒ€ ë¦¬ë”
        self.tech_lead = autogen.AssistantAgent(
            name="tech_lead",
            llm_config=base_config,
            system_message="""
            ê¸°ìˆ  ë¦¬ë”ë¡œì„œ ì•„í‚¤í…ì²˜ ê²°ì •ê³¼ ì½”ë“œ ë¦¬ë·°ë¥¼ ë‹´ë‹¹í•©ë‹ˆë‹¤.
            - ê¸°ìˆ  ìŠ¤íƒ ì„ íƒê³¼ ì•„í‚¤í…ì²˜ ì„¤ê³„
            - ì½”ë“œ í’ˆì§ˆê³¼ í‘œì¤€ ê´€ë¦¬
            - íŒ€ì› ê°„ ì˜ê²¬ ì¡°ìœ¨
            - ê¸°ìˆ ì  ìœ„í—˜ ìš”ì†Œ ì‹ë³„
            """
        )

        # í’€ìŠ¤íƒ ê°œë°œì
        self.fullstack_dev = autogen.AssistantAgent(
            name="fullstack_developer",
            llm_config=base_config,
            system_message="""
            í’€ìŠ¤íƒ ê°œë°œìë¡œì„œ í”„ë¡ íŠ¸ì—”ë“œì™€ ë°±ì—”ë“œë¥¼ ëª¨ë‘ ë‹´ë‹¹í•©ë‹ˆë‹¤.
            - React/Vue.js í”„ë¡ íŠ¸ì—”ë“œ ê°œë°œ
            - Node.js/Python ë°±ì—”ë“œ ê°œë°œ
            - API ì„¤ê³„ ë° ë°ì´í„°ë² ì´ìŠ¤ ì—°ë™
            - ë°˜ì‘í˜• UI/UX êµ¬í˜„
            """
        )

        # DevOps ì—”ì§€ë‹ˆì–´
        self.devops = autogen.AssistantAgent(
            name="devops_engineer",
            llm_config=base_config,
            system_message="""
            DevOps ì—”ì§€ë‹ˆì–´ë¡œì„œ ë°°í¬ì™€ ì¸í”„ë¼ë¥¼ ë‹´ë‹¹í•©ë‹ˆë‹¤.
            - CI/CD íŒŒì´í”„ë¼ì¸ êµ¬ì¶•
            - Docker, Kubernetes ì»¨í…Œì´ë„ˆ ê´€ë¦¬
            - í´ë¼ìš°ë“œ ì¸í”„ë¼ ì„¤ê³„ (AWS/Azure/GCP)
            - ëª¨ë‹ˆí„°ë§ ë° ë¡œê¹… ì‹œìŠ¤í…œ
            """
        )

        # QA ì—”ì§€ë‹ˆì–´
        self.qa_engineer = autogen.AssistantAgent(
            name="qa_engineer",
            llm_config=base_config,
            system_message="""
            QA ì—”ì§€ë‹ˆì–´ë¡œì„œ í’ˆì§ˆ ë³´ì¦ì„ ë‹´ë‹¹í•©ë‹ˆë‹¤.
            - í…ŒìŠ¤íŠ¸ ê³„íš ìˆ˜ë¦½ ë° ì‹¤í–‰
            - ìë™í™” í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸ ì‘ì„±
            - ë²„ê·¸ ë¦¬í¬íŠ¸ ë° ì¬í˜„ ì‹œë‚˜ë¦¬ì˜¤
            - ì„±ëŠ¥ ë° ë³´ì•ˆ í…ŒìŠ¤íŠ¸
            """
        )

        self.user_proxy = autogen.UserProxyAgent(
            name="product_owner",
            human_input_mode="NEVER",
            code_execution_config={
                "work_dir": "project_workspace",
                "use_docker": True
            }
        )

    def develop_project(self, project_requirements):
        """í”„ë¡œì íŠ¸ ê°œë°œ ìˆ˜í–‰"""
        team = [
            self.user_proxy,
            self.tech_lead,
            self.fullstack_dev,
            self.devops,
            self.qa_engineer
        ]

        groupchat = autogen.GroupChat(
            agents=team,
            messages=[],
            max_round=100,
            speaker_selection_method="auto"
        )

        manager = autogen.GroupChatManager(
            groupchat=groupchat,
            llm_config={"config_list": self.config_list}
        )

        self.user_proxy.initiate_chat(
            manager,
            message=f"""
            ìƒˆë¡œìš´ í”„ë¡œì íŠ¸ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤: {project_requirements}

            ê°œë°œ í”„ë¡œì„¸ìŠ¤:
            1. Tech Lead: ê¸°ìˆ  ìŠ¤íƒ ë° ì•„í‚¤í…ì²˜ ì„¤ê³„
            2. Fullstack Dev: í•µì‹¬ ê¸°ëŠ¥ êµ¬í˜„
            3. DevOps: ë°°í¬ í™˜ê²½ êµ¬ì¶•
            4. QA: í…ŒìŠ¤íŠ¸ ê³„íš ë° ì‹¤í–‰
            5. íŒ€ í˜‘ì—…ì„ í†µí•œ ì´ìŠˆ í•´ê²°

            ìµœì¢… ëª©í‘œ: í”„ë¡œë•ì…˜ ë°°í¬ ê°€ëŠ¥í•œ ì™„ì„±ëœ ì• í”Œë¦¬ì¼€ì´ì…˜
            """
        )

# ì‚¬ìš© ì˜ˆì‹œ
dev_team = SoftwareDevelopmentTeam(config_list)
dev_team.develop_project("""
ì˜¨ë¼ì¸ ë¶ë§ˆí¬ ê´€ë¦¬ ì‹œìŠ¤í…œ

ì£¼ìš” ê¸°ëŠ¥:
- ì‚¬ìš©ì íšŒì›ê°€ì…/ë¡œê·¸ì¸
- ë¶ë§ˆí¬ ì¶”ê°€/í¸ì§‘/ì‚­ì œ
- íƒœê·¸ ê¸°ë°˜ ë¶„ë¥˜
- ê²€ìƒ‰ ë° í•„í„°ë§
- ì†Œì…œ ê³µìœ  ê¸°ëŠ¥

ê¸°ìˆ  ìš”êµ¬ì‚¬í•­:
- ë°˜ì‘í˜• ì›¹ ì¸í„°í˜ì´ìŠ¤
- RESTful API
- ì‚¬ìš©ì ì¸ì¦ ë° ê¶Œí•œ ê´€ë¦¬
- ë°ì´í„°ë² ì´ìŠ¤ ìµœì í™”
- í´ë¼ìš°ë“œ ë°°í¬
""")
```

---

## 11. ì°¸ê³  ìë£Œ

### 11.1. ê³µì‹ ë¬¸ì„œ
- **AutoGen GitHub**: https://github.com/microsoft/autogen
- **ê³µì‹ ë¬¸ì„œ**: https://microsoft.github.io/autogen/
- **AutoGen Studio**: https://github.com/microsoft/autogen/tree/main/samples/apps/autogen-studio

### 11.2. ì»¤ë®¤ë‹ˆí‹°
- **Discord**: Microsoft AutoGen Community
- **ë…¼ë¬¸**: "AutoGen: Enabling Next-Gen LLM Applications"
- **YouTube**: AutoGen Tutorial Series

### 11.3. ê´€ë ¨ ë„êµ¬
- **Jupyter Integration**: AutoGen + Jupyter Notebook
- **Docker Images**: ì‚¬ì „ êµ¬ì„±ëœ AutoGen í™˜ê²½
- **VS Code Extension**: AutoGen ê°œë°œ ë„êµ¬

---

## 12. ì²´í¬ë¦¬ìŠ¤íŠ¸

**ê¸°ë³¸ ì„¤ì •:**
- [ ] Python 3.8+ í™˜ê²½ ì¤€ë¹„
- [ ] AutoGen íŒ¨í‚¤ì§€ ì„¤ì¹˜
- [ ] LLM API í‚¤ ì„¤ì •
- [ ] ê¸°ë³¸ ì—ì´ì „íŠ¸ ëŒ€í™” í…ŒìŠ¤íŠ¸

**ë©€í‹° ì—ì´ì „íŠ¸:**
- [ ] 2-3ê°œ ì—ì´ì „íŠ¸ í˜‘ì—… êµ¬í˜„
- [ ] ì—­í• ë³„ ì‹œìŠ¤í…œ ë©”ì‹œì§€ ìµœì í™”
- [ ] ê·¸ë£¹ ì±„íŒ… ê´€ë¦¬ì ì„¤ì •
- [ ] ì¢…ë£Œ ì¡°ê±´ ëª…í™•í™”

**ê³ ê¸‰ ê¸°ëŠ¥:**
- [ ] ì½”ë“œ ì‹¤í–‰ í™˜ê²½ êµ¬ì„±
- [ ] ì¡°ê±´ë¶€ ì›Œí¬í”Œë¡œìš° êµ¬í˜„
- [ ] ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ë„êµ¬ ì ìš©
- [ ] ì˜¤ë¥˜ ì²˜ë¦¬ ë° ë³µêµ¬ ë¡œì§

**í”„ë¡œë•ì…˜:**
- [ ] AutoGen Studio í™œìš©
- [ ] ë³´ì•ˆ ì„¤ì • ê°•í™”
- [ ] ë¹„ìš© ìµœì í™” ì ìš©
- [ ] ë¡œê¹… ë° ë””ë²„ê¹… í™˜ê²½

**2025ë…„ 9ì›” ê¸°ì¤€ ìµœì‹  AutoGen ê¸°ëŠ¥ê³¼ ì‹¤ë¬´ íŒ¨í„´ì„ ë°˜ì˜í•œ ì¢…í•© ê°€ì´ë“œì…ë‹ˆë‹¤.**